{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5689,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004394445420987872,
      "grad_norm": 5.236807823181152,
      "learning_rate": 0.00019915626647917033,
      "loss": 0.2476,
      "step": 25
    },
    {
      "epoch": 0.008788890841975743,
      "grad_norm": 4.880784511566162,
      "learning_rate": 0.00019827737739497276,
      "loss": 0.275,
      "step": 50
    },
    {
      "epoch": 0.013183336262963615,
      "grad_norm": 5.123338222503662,
      "learning_rate": 0.0001973984883107752,
      "loss": 0.3008,
      "step": 75
    },
    {
      "epoch": 0.017577781683951486,
      "grad_norm": 3.6276872158050537,
      "learning_rate": 0.0001965195992265776,
      "loss": 0.2976,
      "step": 100
    },
    {
      "epoch": 0.021972227104939356,
      "grad_norm": 5.468163967132568,
      "learning_rate": 0.00019564071014238003,
      "loss": 0.3071,
      "step": 125
    },
    {
      "epoch": 0.02636667252592723,
      "grad_norm": 4.570960998535156,
      "learning_rate": 0.00019476182105818246,
      "loss": 0.3024,
      "step": 150
    },
    {
      "epoch": 0.0307611179469151,
      "grad_norm": 4.384193420410156,
      "learning_rate": 0.00019391808753735278,
      "loss": 0.3089,
      "step": 175
    },
    {
      "epoch": 0.03515556336790297,
      "grad_norm": 6.134023666381836,
      "learning_rate": 0.00019303919845315521,
      "loss": 0.3193,
      "step": 200
    },
    {
      "epoch": 0.03955000878889084,
      "grad_norm": 5.130946636199951,
      "learning_rate": 0.00019216030936895765,
      "loss": 0.3324,
      "step": 225
    },
    {
      "epoch": 0.04394445420987871,
      "grad_norm": 6.426144599914551,
      "learning_rate": 0.00019128142028476008,
      "loss": 0.3258,
      "step": 250
    },
    {
      "epoch": 0.048338899630866586,
      "grad_norm": 4.998777389526367,
      "learning_rate": 0.0001904025312005625,
      "loss": 0.3489,
      "step": 275
    },
    {
      "epoch": 0.05273334505185446,
      "grad_norm": 6.3740410804748535,
      "learning_rate": 0.00018952364211636494,
      "loss": 0.3278,
      "step": 300
    },
    {
      "epoch": 0.057127790472842326,
      "grad_norm": 5.0419535636901855,
      "learning_rate": 0.00018864475303216735,
      "loss": 0.3525,
      "step": 325
    },
    {
      "epoch": 0.0615222358938302,
      "grad_norm": 6.455982685089111,
      "learning_rate": 0.00018776586394796978,
      "loss": 0.3355,
      "step": 350
    },
    {
      "epoch": 0.06591668131481807,
      "grad_norm": 5.55111026763916,
      "learning_rate": 0.0001868869748637722,
      "loss": 0.3395,
      "step": 375
    },
    {
      "epoch": 0.07031112673580595,
      "grad_norm": 5.600689888000488,
      "learning_rate": 0.00018600808577957462,
      "loss": 0.3411,
      "step": 400
    },
    {
      "epoch": 0.07470557215679381,
      "grad_norm": 5.527029514312744,
      "learning_rate": 0.00018512919669537705,
      "loss": 0.3432,
      "step": 425
    },
    {
      "epoch": 0.07910001757778168,
      "grad_norm": 7.141038417816162,
      "learning_rate": 0.00018425030761117948,
      "loss": 0.3416,
      "step": 450
    },
    {
      "epoch": 0.08349446299876956,
      "grad_norm": 5.322793960571289,
      "learning_rate": 0.0001833714185269819,
      "loss": 0.3332,
      "step": 475
    },
    {
      "epoch": 0.08788890841975742,
      "grad_norm": 5.445427894592285,
      "learning_rate": 0.00018249252944278432,
      "loss": 0.3517,
      "step": 500
    },
    {
      "epoch": 0.09228335384074529,
      "grad_norm": 4.047283172607422,
      "learning_rate": 0.00018161364035858675,
      "loss": 0.3544,
      "step": 525
    },
    {
      "epoch": 0.09667779926173317,
      "grad_norm": 5.0143723487854,
      "learning_rate": 0.00018073475127438918,
      "loss": 0.348,
      "step": 550
    },
    {
      "epoch": 0.10107224468272104,
      "grad_norm": 4.847787857055664,
      "learning_rate": 0.00017985586219019162,
      "loss": 0.341,
      "step": 575
    },
    {
      "epoch": 0.10546669010370892,
      "grad_norm": 4.058062553405762,
      "learning_rate": 0.00017897697310599405,
      "loss": 0.3503,
      "step": 600
    },
    {
      "epoch": 0.10986113552469678,
      "grad_norm": 4.561588287353516,
      "learning_rate": 0.00017809808402179645,
      "loss": 0.3225,
      "step": 625
    },
    {
      "epoch": 0.11425558094568465,
      "grad_norm": 4.3931989669799805,
      "learning_rate": 0.00017721919493759888,
      "loss": 0.3215,
      "step": 650
    },
    {
      "epoch": 0.11865002636667253,
      "grad_norm": 4.939215660095215,
      "learning_rate": 0.00017634030585340132,
      "loss": 0.3366,
      "step": 675
    },
    {
      "epoch": 0.1230444717876604,
      "grad_norm": 4.8004631996154785,
      "learning_rate": 0.00017546141676920372,
      "loss": 0.3394,
      "step": 700
    },
    {
      "epoch": 0.12743891720864828,
      "grad_norm": 6.450831413269043,
      "learning_rate": 0.00017458252768500615,
      "loss": 0.3464,
      "step": 725
    },
    {
      "epoch": 0.13183336262963613,
      "grad_norm": 5.266153335571289,
      "learning_rate": 0.00017370363860080859,
      "loss": 0.3229,
      "step": 750
    },
    {
      "epoch": 0.136227808050624,
      "grad_norm": 6.061757564544678,
      "learning_rate": 0.00017282474951661102,
      "loss": 0.3363,
      "step": 775
    },
    {
      "epoch": 0.1406222534716119,
      "grad_norm": 4.673859119415283,
      "learning_rate": 0.00017194586043241342,
      "loss": 0.314,
      "step": 800
    },
    {
      "epoch": 0.14501669889259974,
      "grad_norm": 6.8967156410217285,
      "learning_rate": 0.00017106697134821586,
      "loss": 0.3448,
      "step": 825
    },
    {
      "epoch": 0.14941114431358762,
      "grad_norm": 4.740516185760498,
      "learning_rate": 0.0001701880822640183,
      "loss": 0.3376,
      "step": 850
    },
    {
      "epoch": 0.1538055897345755,
      "grad_norm": 5.278782367706299,
      "learning_rate": 0.00016930919317982072,
      "loss": 0.3384,
      "step": 875
    },
    {
      "epoch": 0.15820003515556336,
      "grad_norm": 3.9265875816345215,
      "learning_rate": 0.00016843030409562315,
      "loss": 0.3307,
      "step": 900
    },
    {
      "epoch": 0.16259448057655124,
      "grad_norm": 5.860733985900879,
      "learning_rate": 0.00016755141501142558,
      "loss": 0.3474,
      "step": 925
    },
    {
      "epoch": 0.16698892599753912,
      "grad_norm": 4.569789409637451,
      "learning_rate": 0.0001667076814905959,
      "loss": 0.32,
      "step": 950
    },
    {
      "epoch": 0.17138337141852697,
      "grad_norm": 4.67699670791626,
      "learning_rate": 0.00016582879240639834,
      "loss": 0.3205,
      "step": 975
    },
    {
      "epoch": 0.17577781683951485,
      "grad_norm": 4.1751580238342285,
      "learning_rate": 0.00016494990332220074,
      "loss": 0.324,
      "step": 1000
    },
    {
      "epoch": 0.18017226226050273,
      "grad_norm": 4.986656188964844,
      "learning_rate": 0.00016407101423800317,
      "loss": 0.3186,
      "step": 1025
    },
    {
      "epoch": 0.18456670768149058,
      "grad_norm": 4.6358113288879395,
      "learning_rate": 0.0001631921251538056,
      "loss": 0.3478,
      "step": 1050
    },
    {
      "epoch": 0.18896115310247846,
      "grad_norm": 5.323032855987549,
      "learning_rate": 0.000162313236069608,
      "loss": 0.3324,
      "step": 1075
    },
    {
      "epoch": 0.19335559852346634,
      "grad_norm": 5.078690052032471,
      "learning_rate": 0.00016143434698541044,
      "loss": 0.3417,
      "step": 1100
    },
    {
      "epoch": 0.19775004394445422,
      "grad_norm": 4.563243865966797,
      "learning_rate": 0.00016055545790121287,
      "loss": 0.3571,
      "step": 1125
    },
    {
      "epoch": 0.20214448936544208,
      "grad_norm": 4.448254585266113,
      "learning_rate": 0.00015967656881701528,
      "loss": 0.3099,
      "step": 1150
    },
    {
      "epoch": 0.20653893478642996,
      "grad_norm": 5.58157205581665,
      "learning_rate": 0.0001587976797328177,
      "loss": 0.3064,
      "step": 1175
    },
    {
      "epoch": 0.21093338020741784,
      "grad_norm": 4.978571891784668,
      "learning_rate": 0.00015791879064862014,
      "loss": 0.3063,
      "step": 1200
    },
    {
      "epoch": 0.2153278256284057,
      "grad_norm": 4.389284133911133,
      "learning_rate": 0.00015703990156442258,
      "loss": 0.342,
      "step": 1225
    },
    {
      "epoch": 0.21972227104939357,
      "grad_norm": 5.15391731262207,
      "learning_rate": 0.000156161012480225,
      "loss": 0.3356,
      "step": 1250
    },
    {
      "epoch": 0.22411671647038145,
      "grad_norm": 4.8584089279174805,
      "learning_rate": 0.00015528212339602744,
      "loss": 0.3116,
      "step": 1275
    },
    {
      "epoch": 0.2285111618913693,
      "grad_norm": 5.5477190017700195,
      "learning_rate": 0.00015440323431182985,
      "loss": 0.3079,
      "step": 1300
    },
    {
      "epoch": 0.23290560731235718,
      "grad_norm": 5.851944923400879,
      "learning_rate": 0.00015352434522763228,
      "loss": 0.3142,
      "step": 1325
    },
    {
      "epoch": 0.23730005273334506,
      "grad_norm": 4.203130722045898,
      "learning_rate": 0.0001526454561434347,
      "loss": 0.3021,
      "step": 1350
    },
    {
      "epoch": 0.24169449815433292,
      "grad_norm": 4.108596324920654,
      "learning_rate": 0.00015176656705923714,
      "loss": 0.3055,
      "step": 1375
    },
    {
      "epoch": 0.2460889435753208,
      "grad_norm": 4.574544429779053,
      "learning_rate": 0.00015088767797503955,
      "loss": 0.3344,
      "step": 1400
    },
    {
      "epoch": 0.2504833889963087,
      "grad_norm": 5.4358601570129395,
      "learning_rate": 0.00015000878889084198,
      "loss": 0.303,
      "step": 1425
    },
    {
      "epoch": 0.25487783441729656,
      "grad_norm": 4.302306652069092,
      "learning_rate": 0.0001491298998066444,
      "loss": 0.3158,
      "step": 1450
    },
    {
      "epoch": 0.25927227983828444,
      "grad_norm": 6.054989814758301,
      "learning_rate": 0.00014825101072244682,
      "loss": 0.3431,
      "step": 1475
    },
    {
      "epoch": 0.26366672525927226,
      "grad_norm": 4.4922261238098145,
      "learning_rate": 0.00014737212163824925,
      "loss": 0.2977,
      "step": 1500
    },
    {
      "epoch": 0.26806117068026014,
      "grad_norm": 4.8708953857421875,
      "learning_rate": 0.0001464932325540517,
      "loss": 0.3118,
      "step": 1525
    },
    {
      "epoch": 0.272455616101248,
      "grad_norm": 4.7276225090026855,
      "learning_rate": 0.0001456143434698541,
      "loss": 0.3096,
      "step": 1550
    },
    {
      "epoch": 0.2768500615222359,
      "grad_norm": 4.523395538330078,
      "learning_rate": 0.00014473545438565654,
      "loss": 0.3064,
      "step": 1575
    },
    {
      "epoch": 0.2812445069432238,
      "grad_norm": 4.154234886169434,
      "learning_rate": 0.00014385656530145898,
      "loss": 0.295,
      "step": 1600
    },
    {
      "epoch": 0.28563895236421166,
      "grad_norm": 4.9997382164001465,
      "learning_rate": 0.00014297767621726138,
      "loss": 0.3118,
      "step": 1625
    },
    {
      "epoch": 0.2900333977851995,
      "grad_norm": 4.83870267868042,
      "learning_rate": 0.00014209878713306381,
      "loss": 0.3074,
      "step": 1650
    },
    {
      "epoch": 0.29442784320618737,
      "grad_norm": 4.85009765625,
      "learning_rate": 0.00014121989804886625,
      "loss": 0.3218,
      "step": 1675
    },
    {
      "epoch": 0.29882228862717525,
      "grad_norm": 4.136562347412109,
      "learning_rate": 0.00014034100896466865,
      "loss": 0.3012,
      "step": 1700
    },
    {
      "epoch": 0.30321673404816313,
      "grad_norm": 4.539144992828369,
      "learning_rate": 0.00013946211988047108,
      "loss": 0.2878,
      "step": 1725
    },
    {
      "epoch": 0.307611179469151,
      "grad_norm": 4.66489839553833,
      "learning_rate": 0.00013858323079627352,
      "loss": 0.2824,
      "step": 1750
    },
    {
      "epoch": 0.3120056248901389,
      "grad_norm": 4.902602672576904,
      "learning_rate": 0.00013770434171207595,
      "loss": 0.3135,
      "step": 1775
    },
    {
      "epoch": 0.3164000703111267,
      "grad_norm": 2.8865480422973633,
      "learning_rate": 0.00013682545262787835,
      "loss": 0.2986,
      "step": 1800
    },
    {
      "epoch": 0.3207945157321146,
      "grad_norm": 4.117831707000732,
      "learning_rate": 0.0001359465635436808,
      "loss": 0.2987,
      "step": 1825
    },
    {
      "epoch": 0.3251889611531025,
      "grad_norm": 3.8996808528900146,
      "learning_rate": 0.00013506767445948322,
      "loss": 0.2869,
      "step": 1850
    },
    {
      "epoch": 0.32958340657409035,
      "grad_norm": 4.824930191040039,
      "learning_rate": 0.00013418878537528565,
      "loss": 0.2858,
      "step": 1875
    },
    {
      "epoch": 0.33397785199507823,
      "grad_norm": 5.230655670166016,
      "learning_rate": 0.00013330989629108808,
      "loss": 0.3167,
      "step": 1900
    },
    {
      "epoch": 0.3383722974160661,
      "grad_norm": 4.7286481857299805,
      "learning_rate": 0.0001324310072068905,
      "loss": 0.2765,
      "step": 1925
    },
    {
      "epoch": 0.34276674283705394,
      "grad_norm": 4.865993976593018,
      "learning_rate": 0.00013155211812269292,
      "loss": 0.2926,
      "step": 1950
    },
    {
      "epoch": 0.3471611882580418,
      "grad_norm": 3.8952760696411133,
      "learning_rate": 0.00013067322903849535,
      "loss": 0.3046,
      "step": 1975
    },
    {
      "epoch": 0.3515556336790297,
      "grad_norm": 3.8865809440612793,
      "learning_rate": 0.00012979433995429778,
      "loss": 0.2877,
      "step": 2000
    },
    {
      "epoch": 0.3559500791000176,
      "grad_norm": 5.518401145935059,
      "learning_rate": 0.0001289154508701002,
      "loss": 0.2942,
      "step": 2025
    },
    {
      "epoch": 0.36034452452100546,
      "grad_norm": 5.124645709991455,
      "learning_rate": 0.00012803656178590262,
      "loss": 0.2813,
      "step": 2050
    },
    {
      "epoch": 0.36473896994199334,
      "grad_norm": 4.027214050292969,
      "learning_rate": 0.00012715767270170505,
      "loss": 0.2722,
      "step": 2075
    },
    {
      "epoch": 0.36913341536298117,
      "grad_norm": 4.160928726196289,
      "learning_rate": 0.00012627878361750746,
      "loss": 0.2679,
      "step": 2100
    },
    {
      "epoch": 0.37352786078396905,
      "grad_norm": 4.083119869232178,
      "learning_rate": 0.0001253998945333099,
      "loss": 0.2605,
      "step": 2125
    },
    {
      "epoch": 0.3779223062049569,
      "grad_norm": 3.6836652755737305,
      "learning_rate": 0.00012452100544911235,
      "loss": 0.2819,
      "step": 2150
    },
    {
      "epoch": 0.3823167516259448,
      "grad_norm": 4.031534671783447,
      "learning_rate": 0.00012364211636491475,
      "loss": 0.2715,
      "step": 2175
    },
    {
      "epoch": 0.3867111970469327,
      "grad_norm": 4.260400295257568,
      "learning_rate": 0.00012276322728071719,
      "loss": 0.283,
      "step": 2200
    },
    {
      "epoch": 0.39110564246792057,
      "grad_norm": 4.307407855987549,
      "learning_rate": 0.0001218843381965196,
      "loss": 0.2545,
      "step": 2225
    },
    {
      "epoch": 0.39550008788890845,
      "grad_norm": 4.000156402587891,
      "learning_rate": 0.00012100544911232204,
      "loss": 0.2651,
      "step": 2250
    },
    {
      "epoch": 0.39989453330989627,
      "grad_norm": 5.4303083419799805,
      "learning_rate": 0.00012012656002812446,
      "loss": 0.2696,
      "step": 2275
    },
    {
      "epoch": 0.40428897873088415,
      "grad_norm": 3.785416841506958,
      "learning_rate": 0.00011924767094392689,
      "loss": 0.2877,
      "step": 2300
    },
    {
      "epoch": 0.40868342415187203,
      "grad_norm": 4.982220649719238,
      "learning_rate": 0.0001183687818597293,
      "loss": 0.2642,
      "step": 2325
    },
    {
      "epoch": 0.4130778695728599,
      "grad_norm": 4.565971374511719,
      "learning_rate": 0.00011748989277553172,
      "loss": 0.2953,
      "step": 2350
    },
    {
      "epoch": 0.4174723149938478,
      "grad_norm": 4.118102550506592,
      "learning_rate": 0.00011661100369133416,
      "loss": 0.2832,
      "step": 2375
    },
    {
      "epoch": 0.4218667604148357,
      "grad_norm": 4.298951625823975,
      "learning_rate": 0.00011573211460713658,
      "loss": 0.2766,
      "step": 2400
    },
    {
      "epoch": 0.4262612058358235,
      "grad_norm": 4.868335247039795,
      "learning_rate": 0.00011485322552293901,
      "loss": 0.2742,
      "step": 2425
    },
    {
      "epoch": 0.4306556512568114,
      "grad_norm": 4.6476969718933105,
      "learning_rate": 0.00011397433643874145,
      "loss": 0.2767,
      "step": 2450
    },
    {
      "epoch": 0.43505009667779926,
      "grad_norm": 4.198013782501221,
      "learning_rate": 0.00011309544735454387,
      "loss": 0.2707,
      "step": 2475
    },
    {
      "epoch": 0.43944454209878714,
      "grad_norm": 3.5703608989715576,
      "learning_rate": 0.00011221655827034629,
      "loss": 0.2688,
      "step": 2500
    },
    {
      "epoch": 0.443838987519775,
      "grad_norm": 3.9164211750030518,
      "learning_rate": 0.00011133766918614872,
      "loss": 0.2698,
      "step": 2525
    },
    {
      "epoch": 0.4482334329407629,
      "grad_norm": 5.4595770835876465,
      "learning_rate": 0.00011045878010195114,
      "loss": 0.2818,
      "step": 2550
    },
    {
      "epoch": 0.4526278783617507,
      "grad_norm": 3.5389201641082764,
      "learning_rate": 0.00010957989101775357,
      "loss": 0.256,
      "step": 2575
    },
    {
      "epoch": 0.4570223237827386,
      "grad_norm": 2.6363415718078613,
      "learning_rate": 0.00010870100193355599,
      "loss": 0.2659,
      "step": 2600
    },
    {
      "epoch": 0.4614167692037265,
      "grad_norm": 4.497704029083252,
      "learning_rate": 0.00010782211284935841,
      "loss": 0.2557,
      "step": 2625
    },
    {
      "epoch": 0.46581121462471436,
      "grad_norm": 3.9964277744293213,
      "learning_rate": 0.00010694322376516084,
      "loss": 0.2833,
      "step": 2650
    },
    {
      "epoch": 0.47020566004570225,
      "grad_norm": 4.054657459259033,
      "learning_rate": 0.00010606433468096326,
      "loss": 0.2709,
      "step": 2675
    },
    {
      "epoch": 0.4746001054666901,
      "grad_norm": 3.2756481170654297,
      "learning_rate": 0.00010518544559676568,
      "loss": 0.2706,
      "step": 2700
    },
    {
      "epoch": 0.47899455088767795,
      "grad_norm": 3.9063825607299805,
      "learning_rate": 0.00010430655651256811,
      "loss": 0.2612,
      "step": 2725
    },
    {
      "epoch": 0.48338899630866583,
      "grad_norm": 3.804436445236206,
      "learning_rate": 0.00010342766742837053,
      "loss": 0.2658,
      "step": 2750
    },
    {
      "epoch": 0.4877834417296537,
      "grad_norm": 2.4848439693450928,
      "learning_rate": 0.00010254877834417298,
      "loss": 0.2472,
      "step": 2775
    },
    {
      "epoch": 0.4921778871506416,
      "grad_norm": 3.48408579826355,
      "learning_rate": 0.00010166988925997541,
      "loss": 0.2566,
      "step": 2800
    },
    {
      "epoch": 0.49657233257162947,
      "grad_norm": 2.7695837020874023,
      "learning_rate": 0.00010079100017577783,
      "loss": 0.2691,
      "step": 2825
    },
    {
      "epoch": 0.5009667779926174,
      "grad_norm": 3.447716236114502,
      "learning_rate": 9.991211109158025e-05,
      "loss": 0.2526,
      "step": 2850
    },
    {
      "epoch": 0.5053612234136052,
      "grad_norm": 3.389113187789917,
      "learning_rate": 9.903322200738268e-05,
      "loss": 0.2603,
      "step": 2875
    },
    {
      "epoch": 0.5097556688345931,
      "grad_norm": 2.7258572578430176,
      "learning_rate": 9.81543329231851e-05,
      "loss": 0.2513,
      "step": 2900
    },
    {
      "epoch": 0.514150114255581,
      "grad_norm": 5.036204814910889,
      "learning_rate": 9.727544383898753e-05,
      "loss": 0.2574,
      "step": 2925
    },
    {
      "epoch": 0.5185445596765689,
      "grad_norm": 3.5710177421569824,
      "learning_rate": 9.639655475478995e-05,
      "loss": 0.2464,
      "step": 2950
    },
    {
      "epoch": 0.5229390050975566,
      "grad_norm": 3.882219076156616,
      "learning_rate": 9.551766567059237e-05,
      "loss": 0.248,
      "step": 2975
    },
    {
      "epoch": 0.5273334505185445,
      "grad_norm": 3.870147466659546,
      "learning_rate": 9.463877658639481e-05,
      "loss": 0.259,
      "step": 3000
    },
    {
      "epoch": 0.5317278959395324,
      "grad_norm": 3.2087442874908447,
      "learning_rate": 9.375988750219723e-05,
      "loss": 0.2213,
      "step": 3025
    },
    {
      "epoch": 0.5361223413605203,
      "grad_norm": 4.130318641662598,
      "learning_rate": 9.288099841799965e-05,
      "loss": 0.2473,
      "step": 3050
    },
    {
      "epoch": 0.5405167867815082,
      "grad_norm": 4.055572509765625,
      "learning_rate": 9.200210933380208e-05,
      "loss": 0.2309,
      "step": 3075
    },
    {
      "epoch": 0.544911232202496,
      "grad_norm": 3.3298168182373047,
      "learning_rate": 9.11232202496045e-05,
      "loss": 0.2496,
      "step": 3100
    },
    {
      "epoch": 0.5493056776234839,
      "grad_norm": 3.069962739944458,
      "learning_rate": 9.024433116540693e-05,
      "loss": 0.2382,
      "step": 3125
    },
    {
      "epoch": 0.5537001230444718,
      "grad_norm": 4.103262901306152,
      "learning_rate": 8.936544208120936e-05,
      "loss": 0.2824,
      "step": 3150
    },
    {
      "epoch": 0.5580945684654597,
      "grad_norm": 3.045297622680664,
      "learning_rate": 8.848655299701178e-05,
      "loss": 0.2436,
      "step": 3175
    },
    {
      "epoch": 0.5624890138864476,
      "grad_norm": 3.4144444465637207,
      "learning_rate": 8.760766391281421e-05,
      "loss": 0.2339,
      "step": 3200
    },
    {
      "epoch": 0.5668834593074354,
      "grad_norm": 3.2652840614318848,
      "learning_rate": 8.672877482861663e-05,
      "loss": 0.2546,
      "step": 3225
    },
    {
      "epoch": 0.5712779047284233,
      "grad_norm": 3.376514196395874,
      "learning_rate": 8.584988574441905e-05,
      "loss": 0.2815,
      "step": 3250
    },
    {
      "epoch": 0.5756723501494111,
      "grad_norm": 4.204913139343262,
      "learning_rate": 8.497099666022148e-05,
      "loss": 0.2456,
      "step": 3275
    },
    {
      "epoch": 0.580066795570399,
      "grad_norm": 4.036107063293457,
      "learning_rate": 8.409210757602392e-05,
      "loss": 0.2444,
      "step": 3300
    },
    {
      "epoch": 0.5844612409913869,
      "grad_norm": 3.317033290863037,
      "learning_rate": 8.321321849182633e-05,
      "loss": 0.2489,
      "step": 3325
    },
    {
      "epoch": 0.5888556864123747,
      "grad_norm": 4.109902858734131,
      "learning_rate": 8.233432940762877e-05,
      "loss": 0.2594,
      "step": 3350
    },
    {
      "epoch": 0.5932501318333626,
      "grad_norm": 3.9324069023132324,
      "learning_rate": 8.145544032343118e-05,
      "loss": 0.2425,
      "step": 3375
    },
    {
      "epoch": 0.5976445772543505,
      "grad_norm": 4.6635966300964355,
      "learning_rate": 8.057655123923362e-05,
      "loss": 0.243,
      "step": 3400
    },
    {
      "epoch": 0.6020390226753384,
      "grad_norm": 3.7456107139587402,
      "learning_rate": 7.969766215503604e-05,
      "loss": 0.2477,
      "step": 3425
    },
    {
      "epoch": 0.6064334680963263,
      "grad_norm": 3.1284549236297607,
      "learning_rate": 7.881877307083845e-05,
      "loss": 0.2424,
      "step": 3450
    },
    {
      "epoch": 0.6108279135173141,
      "grad_norm": 4.196728706359863,
      "learning_rate": 7.79398839866409e-05,
      "loss": 0.2256,
      "step": 3475
    },
    {
      "epoch": 0.615222358938302,
      "grad_norm": 5.473304748535156,
      "learning_rate": 7.706099490244332e-05,
      "loss": 0.2732,
      "step": 3500
    },
    {
      "epoch": 0.6196168043592899,
      "grad_norm": 4.029904842376709,
      "learning_rate": 7.618210581824574e-05,
      "loss": 0.2367,
      "step": 3525
    },
    {
      "epoch": 0.6240112497802778,
      "grad_norm": 3.4871792793273926,
      "learning_rate": 7.530321673404817e-05,
      "loss": 0.2373,
      "step": 3550
    },
    {
      "epoch": 0.6284056952012655,
      "grad_norm": 3.8540399074554443,
      "learning_rate": 7.442432764985059e-05,
      "loss": 0.2302,
      "step": 3575
    },
    {
      "epoch": 0.6328001406222534,
      "grad_norm": 2.8822336196899414,
      "learning_rate": 7.354543856565302e-05,
      "loss": 0.24,
      "step": 3600
    },
    {
      "epoch": 0.6371945860432413,
      "grad_norm": 3.3150391578674316,
      "learning_rate": 7.266654948145545e-05,
      "loss": 0.2406,
      "step": 3625
    },
    {
      "epoch": 0.6415890314642292,
      "grad_norm": 3.0992908477783203,
      "learning_rate": 7.178766039725787e-05,
      "loss": 0.2413,
      "step": 3650
    },
    {
      "epoch": 0.6459834768852171,
      "grad_norm": 2.4501876831054688,
      "learning_rate": 7.09087713130603e-05,
      "loss": 0.231,
      "step": 3675
    },
    {
      "epoch": 0.650377922306205,
      "grad_norm": 2.4205589294433594,
      "learning_rate": 7.002988222886272e-05,
      "loss": 0.244,
      "step": 3700
    },
    {
      "epoch": 0.6547723677271928,
      "grad_norm": 3.0252532958984375,
      "learning_rate": 6.915099314466514e-05,
      "loss": 0.2212,
      "step": 3725
    },
    {
      "epoch": 0.6591668131481807,
      "grad_norm": 4.1917805671691895,
      "learning_rate": 6.827210406046757e-05,
      "loss": 0.229,
      "step": 3750
    },
    {
      "epoch": 0.6635612585691686,
      "grad_norm": 2.999464511871338,
      "learning_rate": 6.739321497627e-05,
      "loss": 0.2411,
      "step": 3775
    },
    {
      "epoch": 0.6679557039901565,
      "grad_norm": 4.551303863525391,
      "learning_rate": 6.651432589207242e-05,
      "loss": 0.2337,
      "step": 3800
    },
    {
      "epoch": 0.6723501494111443,
      "grad_norm": 2.8382070064544678,
      "learning_rate": 6.563543680787485e-05,
      "loss": 0.2223,
      "step": 3825
    },
    {
      "epoch": 0.6767445948321322,
      "grad_norm": 3.908015727996826,
      "learning_rate": 6.475654772367727e-05,
      "loss": 0.2358,
      "step": 3850
    },
    {
      "epoch": 0.6811390402531201,
      "grad_norm": 2.963881731033325,
      "learning_rate": 6.387765863947969e-05,
      "loss": 0.2441,
      "step": 3875
    },
    {
      "epoch": 0.6855334856741079,
      "grad_norm": 3.6418330669403076,
      "learning_rate": 6.299876955528212e-05,
      "loss": 0.2355,
      "step": 3900
    },
    {
      "epoch": 0.6899279310950958,
      "grad_norm": 3.406949520111084,
      "learning_rate": 6.211988047108456e-05,
      "loss": 0.2321,
      "step": 3925
    },
    {
      "epoch": 0.6943223765160836,
      "grad_norm": 3.2308216094970703,
      "learning_rate": 6.124099138688697e-05,
      "loss": 0.2191,
      "step": 3950
    },
    {
      "epoch": 0.6987168219370715,
      "grad_norm": 1.8848520517349243,
      "learning_rate": 6.036210230268941e-05,
      "loss": 0.2158,
      "step": 3975
    },
    {
      "epoch": 0.7031112673580594,
      "grad_norm": 2.70928692817688,
      "learning_rate": 5.9483213218491826e-05,
      "loss": 0.2239,
      "step": 4000
    },
    {
      "epoch": 0.7075057127790473,
      "grad_norm": 2.9040367603302,
      "learning_rate": 5.860432413429425e-05,
      "loss": 0.2088,
      "step": 4025
    },
    {
      "epoch": 0.7119001582000352,
      "grad_norm": 2.42144775390625,
      "learning_rate": 5.7725435050096676e-05,
      "loss": 0.2432,
      "step": 4050
    },
    {
      "epoch": 0.716294603621023,
      "grad_norm": 2.6675636768341064,
      "learning_rate": 5.684654596589911e-05,
      "loss": 0.2194,
      "step": 4075
    },
    {
      "epoch": 0.7206890490420109,
      "grad_norm": 7.618408203125,
      "learning_rate": 5.5967656881701534e-05,
      "loss": 0.2276,
      "step": 4100
    },
    {
      "epoch": 0.7250834944629988,
      "grad_norm": 3.4572646617889404,
      "learning_rate": 5.508876779750396e-05,
      "loss": 0.2184,
      "step": 4125
    },
    {
      "epoch": 0.7294779398839867,
      "grad_norm": 2.0879037380218506,
      "learning_rate": 5.4209878713306385e-05,
      "loss": 0.2337,
      "step": 4150
    },
    {
      "epoch": 0.7338723853049746,
      "grad_norm": 2.0870323181152344,
      "learning_rate": 5.333098962910881e-05,
      "loss": 0.2261,
      "step": 4175
    },
    {
      "epoch": 0.7382668307259623,
      "grad_norm": 3.6500744819641113,
      "learning_rate": 5.245210054491123e-05,
      "loss": 0.2357,
      "step": 4200
    },
    {
      "epoch": 0.7426612761469502,
      "grad_norm": 3.1067700386047363,
      "learning_rate": 5.1573211460713654e-05,
      "loss": 0.2124,
      "step": 4225
    },
    {
      "epoch": 0.7470557215679381,
      "grad_norm": 2.6692793369293213,
      "learning_rate": 5.069432237651609e-05,
      "loss": 0.224,
      "step": 4250
    },
    {
      "epoch": 0.751450166988926,
      "grad_norm": 1.9321109056472778,
      "learning_rate": 4.981543329231851e-05,
      "loss": 0.2182,
      "step": 4275
    },
    {
      "epoch": 0.7558446124099139,
      "grad_norm": 4.025163650512695,
      "learning_rate": 4.893654420812094e-05,
      "loss": 0.225,
      "step": 4300
    },
    {
      "epoch": 0.7602390578309017,
      "grad_norm": 3.1275875568389893,
      "learning_rate": 4.805765512392336e-05,
      "loss": 0.2124,
      "step": 4325
    },
    {
      "epoch": 0.7646335032518896,
      "grad_norm": 2.6086583137512207,
      "learning_rate": 4.7178766039725794e-05,
      "loss": 0.2143,
      "step": 4350
    },
    {
      "epoch": 0.7690279486728775,
      "grad_norm": 2.733959674835205,
      "learning_rate": 4.629987695552821e-05,
      "loss": 0.234,
      "step": 4375
    },
    {
      "epoch": 0.7734223940938654,
      "grad_norm": 2.852607488632202,
      "learning_rate": 4.542098787133064e-05,
      "loss": 0.2119,
      "step": 4400
    },
    {
      "epoch": 0.7778168395148533,
      "grad_norm": 3.0015816688537598,
      "learning_rate": 4.454209878713307e-05,
      "loss": 0.2187,
      "step": 4425
    },
    {
      "epoch": 0.7822112849358411,
      "grad_norm": 2.0169546604156494,
      "learning_rate": 4.3663209702935496e-05,
      "loss": 0.2058,
      "step": 4450
    },
    {
      "epoch": 0.786605730356829,
      "grad_norm": 2.7268166542053223,
      "learning_rate": 4.2784320618737914e-05,
      "loss": 0.2245,
      "step": 4475
    },
    {
      "epoch": 0.7910001757778169,
      "grad_norm": 3.7166287899017334,
      "learning_rate": 4.190543153454034e-05,
      "loss": 0.2057,
      "step": 4500
    },
    {
      "epoch": 0.7953946211988047,
      "grad_norm": 3.1565375328063965,
      "learning_rate": 4.102654245034277e-05,
      "loss": 0.2066,
      "step": 4525
    },
    {
      "epoch": 0.7997890666197925,
      "grad_norm": 2.5028767585754395,
      "learning_rate": 4.014765336614519e-05,
      "loss": 0.216,
      "step": 4550
    },
    {
      "epoch": 0.8041835120407804,
      "grad_norm": 3.5927324295043945,
      "learning_rate": 3.9268764281947616e-05,
      "loss": 0.2149,
      "step": 4575
    },
    {
      "epoch": 0.8085779574617683,
      "grad_norm": 3.907896041870117,
      "learning_rate": 3.838987519775005e-05,
      "loss": 0.2151,
      "step": 4600
    },
    {
      "epoch": 0.8129724028827562,
      "grad_norm": 2.307016134262085,
      "learning_rate": 3.7510986113552473e-05,
      "loss": 0.2071,
      "step": 4625
    },
    {
      "epoch": 0.8173668483037441,
      "grad_norm": 2.3309381008148193,
      "learning_rate": 3.663209702935489e-05,
      "loss": 0.2112,
      "step": 4650
    },
    {
      "epoch": 0.821761293724732,
      "grad_norm": 2.5221970081329346,
      "learning_rate": 3.5753207945157324e-05,
      "loss": 0.2111,
      "step": 4675
    },
    {
      "epoch": 0.8261557391457198,
      "grad_norm": 2.949401378631592,
      "learning_rate": 3.487431886095975e-05,
      "loss": 0.2101,
      "step": 4700
    },
    {
      "epoch": 0.8305501845667077,
      "grad_norm": 3.4352030754089355,
      "learning_rate": 3.3995429776762175e-05,
      "loss": 0.2115,
      "step": 4725
    },
    {
      "epoch": 0.8349446299876956,
      "grad_norm": 2.556837558746338,
      "learning_rate": 3.31165406925646e-05,
      "loss": 0.2228,
      "step": 4750
    },
    {
      "epoch": 0.8393390754086835,
      "grad_norm": 2.7016172409057617,
      "learning_rate": 3.2237651608367026e-05,
      "loss": 0.2269,
      "step": 4775
    },
    {
      "epoch": 0.8437335208296713,
      "grad_norm": 2.3386597633361816,
      "learning_rate": 3.135876252416945e-05,
      "loss": 0.1992,
      "step": 4800
    },
    {
      "epoch": 0.8481279662506591,
      "grad_norm": 3.3948302268981934,
      "learning_rate": 3.047987343997188e-05,
      "loss": 0.2008,
      "step": 4825
    },
    {
      "epoch": 0.852522411671647,
      "grad_norm": 3.224426507949829,
      "learning_rate": 2.9600984355774302e-05,
      "loss": 0.2016,
      "step": 4850
    },
    {
      "epoch": 0.8569168570926349,
      "grad_norm": 1.8667799234390259,
      "learning_rate": 2.8722095271576727e-05,
      "loss": 0.2135,
      "step": 4875
    },
    {
      "epoch": 0.8613113025136228,
      "grad_norm": 3.7031874656677246,
      "learning_rate": 2.7843206187379156e-05,
      "loss": 0.2154,
      "step": 4900
    },
    {
      "epoch": 0.8657057479346106,
      "grad_norm": 3.2202038764953613,
      "learning_rate": 2.696431710318158e-05,
      "loss": 0.2011,
      "step": 4925
    },
    {
      "epoch": 0.8701001933555985,
      "grad_norm": 3.3601064682006836,
      "learning_rate": 2.6085428018984003e-05,
      "loss": 0.2172,
      "step": 4950
    },
    {
      "epoch": 0.8744946387765864,
      "grad_norm": 2.8399136066436768,
      "learning_rate": 2.5206538934786432e-05,
      "loss": 0.2014,
      "step": 4975
    },
    {
      "epoch": 0.8788890841975743,
      "grad_norm": 3.3360886573791504,
      "learning_rate": 2.4327649850588857e-05,
      "loss": 0.2154,
      "step": 5000
    },
    {
      "epoch": 0.8832835296185622,
      "grad_norm": 2.181410551071167,
      "learning_rate": 2.3448760766391283e-05,
      "loss": 0.2098,
      "step": 5025
    },
    {
      "epoch": 0.88767797503955,
      "grad_norm": 2.5273325443267822,
      "learning_rate": 2.2569871682193708e-05,
      "loss": 0.2045,
      "step": 5050
    },
    {
      "epoch": 0.8920724204605379,
      "grad_norm": 2.340473175048828,
      "learning_rate": 2.1690982597996133e-05,
      "loss": 0.2142,
      "step": 5075
    },
    {
      "epoch": 0.8964668658815258,
      "grad_norm": 2.1476008892059326,
      "learning_rate": 2.081209351379856e-05,
      "loss": 0.1978,
      "step": 5100
    },
    {
      "epoch": 0.9008613113025136,
      "grad_norm": 4.005934715270996,
      "learning_rate": 1.9933204429600984e-05,
      "loss": 0.2128,
      "step": 5125
    },
    {
      "epoch": 0.9052557567235014,
      "grad_norm": 1.9353868961334229,
      "learning_rate": 1.9054315345403413e-05,
      "loss": 0.2034,
      "step": 5150
    },
    {
      "epoch": 0.9096502021444893,
      "grad_norm": 3.807006359100342,
      "learning_rate": 1.8175426261205835e-05,
      "loss": 0.2022,
      "step": 5175
    },
    {
      "epoch": 0.9140446475654772,
      "grad_norm": 2.760385513305664,
      "learning_rate": 1.7296537177008264e-05,
      "loss": 0.2167,
      "step": 5200
    },
    {
      "epoch": 0.9184390929864651,
      "grad_norm": 2.2418861389160156,
      "learning_rate": 1.641764809281069e-05,
      "loss": 0.1914,
      "step": 5225
    },
    {
      "epoch": 0.922833538407453,
      "grad_norm": 1.8216404914855957,
      "learning_rate": 1.5538759008613114e-05,
      "loss": 0.1985,
      "step": 5250
    },
    {
      "epoch": 0.9272279838284408,
      "grad_norm": 2.620506525039673,
      "learning_rate": 1.465986992441554e-05,
      "loss": 0.1944,
      "step": 5275
    },
    {
      "epoch": 0.9316224292494287,
      "grad_norm": 1.9739919900894165,
      "learning_rate": 1.3780980840217967e-05,
      "loss": 0.201,
      "step": 5300
    },
    {
      "epoch": 0.9360168746704166,
      "grad_norm": 2.6704628467559814,
      "learning_rate": 1.290209175602039e-05,
      "loss": 0.2015,
      "step": 5325
    },
    {
      "epoch": 0.9404113200914045,
      "grad_norm": 3.229335308074951,
      "learning_rate": 1.2023202671822818e-05,
      "loss": 0.2197,
      "step": 5350
    },
    {
      "epoch": 0.9448057655123924,
      "grad_norm": 2.3172881603240967,
      "learning_rate": 1.1144313587625243e-05,
      "loss": 0.1971,
      "step": 5375
    },
    {
      "epoch": 0.9492002109333803,
      "grad_norm": 2.5938873291015625,
      "learning_rate": 1.0265424503427668e-05,
      "loss": 0.2198,
      "step": 5400
    },
    {
      "epoch": 0.9535946563543681,
      "grad_norm": 3.5265188217163086,
      "learning_rate": 9.386535419230094e-06,
      "loss": 0.211,
      "step": 5425
    },
    {
      "epoch": 0.9579891017753559,
      "grad_norm": 2.6312501430511475,
      "learning_rate": 8.507646335032519e-06,
      "loss": 0.2004,
      "step": 5450
    },
    {
      "epoch": 0.9623835471963438,
      "grad_norm": 3.3209385871887207,
      "learning_rate": 7.628757250834944e-06,
      "loss": 0.2034,
      "step": 5475
    },
    {
      "epoch": 0.9667779926173317,
      "grad_norm": 3.7117702960968018,
      "learning_rate": 6.74986816663737e-06,
      "loss": 0.216,
      "step": 5500
    },
    {
      "epoch": 0.9711724380383195,
      "grad_norm": 2.084404468536377,
      "learning_rate": 5.870979082439797e-06,
      "loss": 0.2102,
      "step": 5525
    },
    {
      "epoch": 0.9755668834593074,
      "grad_norm": 2.9271647930145264,
      "learning_rate": 4.992089998242222e-06,
      "loss": 0.2021,
      "step": 5550
    },
    {
      "epoch": 0.9799613288802953,
      "grad_norm": 2.0415449142456055,
      "learning_rate": 4.113200914044648e-06,
      "loss": 0.2079,
      "step": 5575
    },
    {
      "epoch": 0.9843557743012832,
      "grad_norm": 2.992863655090332,
      "learning_rate": 3.2343118298470733e-06,
      "loss": 0.22,
      "step": 5600
    },
    {
      "epoch": 0.9887502197222711,
      "grad_norm": 2.9489946365356445,
      "learning_rate": 2.355422745649499e-06,
      "loss": 0.2196,
      "step": 5625
    },
    {
      "epoch": 0.9931446651432589,
      "grad_norm": 3.8059566020965576,
      "learning_rate": 1.4765336614519249e-06,
      "loss": 0.2129,
      "step": 5650
    },
    {
      "epoch": 0.9975391105642468,
      "grad_norm": 2.8667242527008057,
      "learning_rate": 5.976445772543506e-07,
      "loss": 0.2109,
      "step": 5675
    }
  ],
  "logging_steps": 25,
  "max_steps": 5689,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.950561664573112e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
