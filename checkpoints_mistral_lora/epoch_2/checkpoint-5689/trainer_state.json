{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5689,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004394445420987872,
      "grad_norm": 5.2631449699401855,
      "learning_rate": 0.00019915626647917033,
      "loss": 0.4587,
      "step": 25
    },
    {
      "epoch": 0.008788890841975743,
      "grad_norm": 4.648928642272949,
      "learning_rate": 0.00019827737739497276,
      "loss": 0.4842,
      "step": 50
    },
    {
      "epoch": 0.013183336262963615,
      "grad_norm": 6.174449920654297,
      "learning_rate": 0.0001973984883107752,
      "loss": 0.5316,
      "step": 75
    },
    {
      "epoch": 0.017577781683951486,
      "grad_norm": 5.935939788818359,
      "learning_rate": 0.0001965195992265776,
      "loss": 0.5259,
      "step": 100
    },
    {
      "epoch": 0.021972227104939356,
      "grad_norm": 6.595353126525879,
      "learning_rate": 0.00019564071014238003,
      "loss": 0.5321,
      "step": 125
    },
    {
      "epoch": 0.02636667252592723,
      "grad_norm": 5.049966812133789,
      "learning_rate": 0.00019476182105818246,
      "loss": 0.5221,
      "step": 150
    },
    {
      "epoch": 0.0307611179469151,
      "grad_norm": 5.829020977020264,
      "learning_rate": 0.0001938829319739849,
      "loss": 0.5101,
      "step": 175
    },
    {
      "epoch": 0.03515556336790297,
      "grad_norm": 6.107892990112305,
      "learning_rate": 0.00019300404288978733,
      "loss": 0.5184,
      "step": 200
    },
    {
      "epoch": 0.03955000878889084,
      "grad_norm": 6.351196765899658,
      "learning_rate": 0.00019216030936895765,
      "loss": 0.5458,
      "step": 225
    },
    {
      "epoch": 0.04394445420987871,
      "grad_norm": 7.086180686950684,
      "learning_rate": 0.00019128142028476008,
      "loss": 0.5467,
      "step": 250
    },
    {
      "epoch": 0.048338899630866586,
      "grad_norm": 6.361139297485352,
      "learning_rate": 0.0001904025312005625,
      "loss": 0.5891,
      "step": 275
    },
    {
      "epoch": 0.05273334505185446,
      "grad_norm": 6.538536071777344,
      "learning_rate": 0.00018952364211636494,
      "loss": 0.5338,
      "step": 300
    },
    {
      "epoch": 0.057127790472842326,
      "grad_norm": 5.081910610198975,
      "learning_rate": 0.00018864475303216735,
      "loss": 0.5592,
      "step": 325
    },
    {
      "epoch": 0.0615222358938302,
      "grad_norm": 6.0970282554626465,
      "learning_rate": 0.00018776586394796978,
      "loss": 0.5357,
      "step": 350
    },
    {
      "epoch": 0.06591668131481807,
      "grad_norm": 7.120819568634033,
      "learning_rate": 0.0001868869748637722,
      "loss": 0.5396,
      "step": 375
    },
    {
      "epoch": 0.07031112673580595,
      "grad_norm": 5.613720893859863,
      "learning_rate": 0.00018600808577957462,
      "loss": 0.5415,
      "step": 400
    },
    {
      "epoch": 0.07470557215679381,
      "grad_norm": 5.6224846839904785,
      "learning_rate": 0.00018512919669537705,
      "loss": 0.5369,
      "step": 425
    },
    {
      "epoch": 0.07910001757778168,
      "grad_norm": 5.782914161682129,
      "learning_rate": 0.00018425030761117948,
      "loss": 0.5375,
      "step": 450
    },
    {
      "epoch": 0.08349446299876956,
      "grad_norm": 5.8301801681518555,
      "learning_rate": 0.0001833714185269819,
      "loss": 0.5268,
      "step": 475
    },
    {
      "epoch": 0.08788890841975742,
      "grad_norm": 5.3205718994140625,
      "learning_rate": 0.00018249252944278432,
      "loss": 0.5463,
      "step": 500
    },
    {
      "epoch": 0.09228335384074529,
      "grad_norm": 4.88338565826416,
      "learning_rate": 0.00018161364035858675,
      "loss": 0.5424,
      "step": 525
    },
    {
      "epoch": 0.09667779926173317,
      "grad_norm": 5.199448585510254,
      "learning_rate": 0.00018073475127438918,
      "loss": 0.5313,
      "step": 550
    },
    {
      "epoch": 0.10107224468272104,
      "grad_norm": 6.849097728729248,
      "learning_rate": 0.00017985586219019162,
      "loss": 0.524,
      "step": 575
    },
    {
      "epoch": 0.10546669010370892,
      "grad_norm": 4.970500469207764,
      "learning_rate": 0.00017897697310599405,
      "loss": 0.5533,
      "step": 600
    },
    {
      "epoch": 0.10986113552469678,
      "grad_norm": 4.680211544036865,
      "learning_rate": 0.00017809808402179645,
      "loss": 0.4961,
      "step": 625
    },
    {
      "epoch": 0.11425558094568465,
      "grad_norm": 5.004963397979736,
      "learning_rate": 0.00017721919493759888,
      "loss": 0.5007,
      "step": 650
    },
    {
      "epoch": 0.11865002636667253,
      "grad_norm": 5.097357749938965,
      "learning_rate": 0.00017634030585340132,
      "loss": 0.5234,
      "step": 675
    },
    {
      "epoch": 0.1230444717876604,
      "grad_norm": 4.825130939483643,
      "learning_rate": 0.00017546141676920372,
      "loss": 0.5215,
      "step": 700
    },
    {
      "epoch": 0.12743891720864828,
      "grad_norm": 6.0550360679626465,
      "learning_rate": 0.00017458252768500615,
      "loss": 0.5306,
      "step": 725
    },
    {
      "epoch": 0.13183336262963613,
      "grad_norm": 6.170552730560303,
      "learning_rate": 0.00017370363860080859,
      "loss": 0.4777,
      "step": 750
    },
    {
      "epoch": 0.136227808050624,
      "grad_norm": 5.394016742706299,
      "learning_rate": 0.00017282474951661102,
      "loss": 0.5152,
      "step": 775
    },
    {
      "epoch": 0.1406222534716119,
      "grad_norm": 4.413163185119629,
      "learning_rate": 0.00017194586043241342,
      "loss": 0.4822,
      "step": 800
    },
    {
      "epoch": 0.14501669889259974,
      "grad_norm": 5.490899085998535,
      "learning_rate": 0.00017106697134821586,
      "loss": 0.5165,
      "step": 825
    },
    {
      "epoch": 0.14941114431358762,
      "grad_norm": 3.7901382446289062,
      "learning_rate": 0.0001701880822640183,
      "loss": 0.5178,
      "step": 850
    },
    {
      "epoch": 0.1538055897345755,
      "grad_norm": 5.942510604858398,
      "learning_rate": 0.00016930919317982072,
      "loss": 0.5137,
      "step": 875
    },
    {
      "epoch": 0.15820003515556336,
      "grad_norm": 3.1772425174713135,
      "learning_rate": 0.00016843030409562315,
      "loss": 0.4927,
      "step": 900
    },
    {
      "epoch": 0.16259448057655124,
      "grad_norm": 4.527931213378906,
      "learning_rate": 0.00016755141501142558,
      "loss": 0.5108,
      "step": 925
    },
    {
      "epoch": 0.16698892599753912,
      "grad_norm": 4.465831756591797,
      "learning_rate": 0.000166672525927228,
      "loss": 0.4773,
      "step": 950
    },
    {
      "epoch": 0.17138337141852697,
      "grad_norm": 5.492602825164795,
      "learning_rate": 0.00016579363684303042,
      "loss": 0.469,
      "step": 975
    },
    {
      "epoch": 0.17577781683951485,
      "grad_norm": 5.054771423339844,
      "learning_rate": 0.00016491474775883285,
      "loss": 0.4868,
      "step": 1000
    },
    {
      "epoch": 0.18017226226050273,
      "grad_norm": 4.518918514251709,
      "learning_rate": 0.00016403585867463526,
      "loss": 0.4602,
      "step": 1025
    },
    {
      "epoch": 0.18456670768149058,
      "grad_norm": 5.526772499084473,
      "learning_rate": 0.0001631569695904377,
      "loss": 0.5113,
      "step": 1050
    },
    {
      "epoch": 0.18896115310247846,
      "grad_norm": 4.353411674499512,
      "learning_rate": 0.00016227808050624012,
      "loss": 0.4995,
      "step": 1075
    },
    {
      "epoch": 0.19335559852346634,
      "grad_norm": 5.469851016998291,
      "learning_rate": 0.00016139919142204253,
      "loss": 0.5017,
      "step": 1100
    },
    {
      "epoch": 0.19775004394445422,
      "grad_norm": 4.8611931800842285,
      "learning_rate": 0.00016052030233784496,
      "loss": 0.5342,
      "step": 1125
    },
    {
      "epoch": 0.20214448936544208,
      "grad_norm": 4.567646026611328,
      "learning_rate": 0.0001596414132536474,
      "loss": 0.4557,
      "step": 1150
    },
    {
      "epoch": 0.20653893478642996,
      "grad_norm": 5.487624168395996,
      "learning_rate": 0.00015876252416944982,
      "loss": 0.4539,
      "step": 1175
    },
    {
      "epoch": 0.21093338020741784,
      "grad_norm": 4.92656946182251,
      "learning_rate": 0.00015788363508525226,
      "loss": 0.4406,
      "step": 1200
    },
    {
      "epoch": 0.2153278256284057,
      "grad_norm": 5.71042537689209,
      "learning_rate": 0.0001570047460010547,
      "loss": 0.4902,
      "step": 1225
    },
    {
      "epoch": 0.21972227104939357,
      "grad_norm": 4.931460380554199,
      "learning_rate": 0.0001561258569168571,
      "loss": 0.4981,
      "step": 1250
    },
    {
      "epoch": 0.22411671647038145,
      "grad_norm": 6.243203639984131,
      "learning_rate": 0.00015524696783265953,
      "loss": 0.4459,
      "step": 1275
    },
    {
      "epoch": 0.2285111618913693,
      "grad_norm": 5.698891639709473,
      "learning_rate": 0.00015436807874846196,
      "loss": 0.4549,
      "step": 1300
    },
    {
      "epoch": 0.23290560731235718,
      "grad_norm": 5.571292400360107,
      "learning_rate": 0.0001534891896642644,
      "loss": 0.4566,
      "step": 1325
    },
    {
      "epoch": 0.23730005273334506,
      "grad_norm": 3.9260334968566895,
      "learning_rate": 0.0001526103005800668,
      "loss": 0.4294,
      "step": 1350
    },
    {
      "epoch": 0.24169449815433292,
      "grad_norm": 4.288829326629639,
      "learning_rate": 0.00015173141149586923,
      "loss": 0.4509,
      "step": 1375
    },
    {
      "epoch": 0.2460889435753208,
      "grad_norm": 5.794532299041748,
      "learning_rate": 0.00015085252241167166,
      "loss": 0.4914,
      "step": 1400
    },
    {
      "epoch": 0.2504833889963087,
      "grad_norm": 6.103457927703857,
      "learning_rate": 0.00014997363332747406,
      "loss": 0.4418,
      "step": 1425
    },
    {
      "epoch": 0.25487783441729656,
      "grad_norm": 4.563736438751221,
      "learning_rate": 0.0001490947442432765,
      "loss": 0.4563,
      "step": 1450
    },
    {
      "epoch": 0.25927227983828444,
      "grad_norm": 5.057814121246338,
      "learning_rate": 0.00014821585515907896,
      "loss": 0.4948,
      "step": 1475
    },
    {
      "epoch": 0.26366672525927226,
      "grad_norm": 4.316300868988037,
      "learning_rate": 0.00014733696607488136,
      "loss": 0.4389,
      "step": 1500
    },
    {
      "epoch": 0.26806117068026014,
      "grad_norm": 5.585056781768799,
      "learning_rate": 0.0001464580769906838,
      "loss": 0.4572,
      "step": 1525
    },
    {
      "epoch": 0.272455616101248,
      "grad_norm": 5.57003927230835,
      "learning_rate": 0.00014557918790648623,
      "loss": 0.4478,
      "step": 1550
    },
    {
      "epoch": 0.2768500615222359,
      "grad_norm": 4.823549747467041,
      "learning_rate": 0.00014470029882228863,
      "loss": 0.446,
      "step": 1575
    },
    {
      "epoch": 0.2812445069432238,
      "grad_norm": 5.436909198760986,
      "learning_rate": 0.00014382140973809106,
      "loss": 0.4293,
      "step": 1600
    },
    {
      "epoch": 0.28563895236421166,
      "grad_norm": 5.099564075469971,
      "learning_rate": 0.0001429425206538935,
      "loss": 0.4446,
      "step": 1625
    },
    {
      "epoch": 0.2900333977851995,
      "grad_norm": 4.873593807220459,
      "learning_rate": 0.0001420636315696959,
      "loss": 0.4393,
      "step": 1650
    },
    {
      "epoch": 0.29442784320618737,
      "grad_norm": 4.154856204986572,
      "learning_rate": 0.00014121989804886625,
      "loss": 0.4612,
      "step": 1675
    },
    {
      "epoch": 0.29882228862717525,
      "grad_norm": 5.367371082305908,
      "learning_rate": 0.00014034100896466865,
      "loss": 0.4331,
      "step": 1700
    },
    {
      "epoch": 0.30321673404816313,
      "grad_norm": 4.792741775512695,
      "learning_rate": 0.00013946211988047108,
      "loss": 0.4236,
      "step": 1725
    },
    {
      "epoch": 0.307611179469151,
      "grad_norm": 4.757347583770752,
      "learning_rate": 0.00013858323079627352,
      "loss": 0.3958,
      "step": 1750
    },
    {
      "epoch": 0.3120056248901389,
      "grad_norm": 3.739805221557617,
      "learning_rate": 0.00013770434171207595,
      "loss": 0.4484,
      "step": 1775
    },
    {
      "epoch": 0.3164000703111267,
      "grad_norm": 4.2754316329956055,
      "learning_rate": 0.00013682545262787835,
      "loss": 0.4388,
      "step": 1800
    },
    {
      "epoch": 0.3207945157321146,
      "grad_norm": 4.235580921173096,
      "learning_rate": 0.0001359465635436808,
      "loss": 0.4249,
      "step": 1825
    },
    {
      "epoch": 0.3251889611531025,
      "grad_norm": 4.49669885635376,
      "learning_rate": 0.00013506767445948322,
      "loss": 0.4157,
      "step": 1850
    },
    {
      "epoch": 0.32958340657409035,
      "grad_norm": 5.923734664916992,
      "learning_rate": 0.00013418878537528565,
      "loss": 0.4095,
      "step": 1875
    },
    {
      "epoch": 0.33397785199507823,
      "grad_norm": 5.246979713439941,
      "learning_rate": 0.00013330989629108808,
      "loss": 0.4491,
      "step": 1900
    },
    {
      "epoch": 0.3383722974160661,
      "grad_norm": 4.113483905792236,
      "learning_rate": 0.0001324310072068905,
      "loss": 0.3967,
      "step": 1925
    },
    {
      "epoch": 0.34276674283705394,
      "grad_norm": 6.054437160491943,
      "learning_rate": 0.00013155211812269292,
      "loss": 0.4182,
      "step": 1950
    },
    {
      "epoch": 0.3471611882580418,
      "grad_norm": 5.114655017852783,
      "learning_rate": 0.00013067322903849535,
      "loss": 0.4303,
      "step": 1975
    },
    {
      "epoch": 0.3515556336790297,
      "grad_norm": 4.577462673187256,
      "learning_rate": 0.00012979433995429778,
      "loss": 0.4129,
      "step": 2000
    },
    {
      "epoch": 0.3559500791000176,
      "grad_norm": 5.2841315269470215,
      "learning_rate": 0.0001289154508701002,
      "loss": 0.4159,
      "step": 2025
    },
    {
      "epoch": 0.36034452452100546,
      "grad_norm": 3.6533305644989014,
      "learning_rate": 0.00012803656178590262,
      "loss": 0.3967,
      "step": 2050
    },
    {
      "epoch": 0.36473896994199334,
      "grad_norm": 3.9503729343414307,
      "learning_rate": 0.00012715767270170505,
      "loss": 0.3802,
      "step": 2075
    },
    {
      "epoch": 0.36913341536298117,
      "grad_norm": 4.3005781173706055,
      "learning_rate": 0.00012627878361750746,
      "loss": 0.3785,
      "step": 2100
    },
    {
      "epoch": 0.37352786078396905,
      "grad_norm": 3.9316916465759277,
      "learning_rate": 0.0001253998945333099,
      "loss": 0.361,
      "step": 2125
    },
    {
      "epoch": 0.3779223062049569,
      "grad_norm": 4.006378173828125,
      "learning_rate": 0.00012452100544911235,
      "loss": 0.3922,
      "step": 2150
    },
    {
      "epoch": 0.3823167516259448,
      "grad_norm": 5.479406356811523,
      "learning_rate": 0.00012364211636491475,
      "loss": 0.3744,
      "step": 2175
    },
    {
      "epoch": 0.3867111970469327,
      "grad_norm": 4.86009407043457,
      "learning_rate": 0.00012276322728071719,
      "loss": 0.3878,
      "step": 2200
    },
    {
      "epoch": 0.39110564246792057,
      "grad_norm": 4.856575012207031,
      "learning_rate": 0.0001218843381965196,
      "loss": 0.3588,
      "step": 2225
    },
    {
      "epoch": 0.39550008788890845,
      "grad_norm": 4.760814666748047,
      "learning_rate": 0.00012100544911232204,
      "loss": 0.3738,
      "step": 2250
    },
    {
      "epoch": 0.39989453330989627,
      "grad_norm": 4.987565994262695,
      "learning_rate": 0.00012012656002812446,
      "loss": 0.3772,
      "step": 2275
    },
    {
      "epoch": 0.40428897873088415,
      "grad_norm": 3.948913812637329,
      "learning_rate": 0.00011924767094392689,
      "loss": 0.394,
      "step": 2300
    },
    {
      "epoch": 0.40868342415187203,
      "grad_norm": 6.141488552093506,
      "learning_rate": 0.0001183687818597293,
      "loss": 0.3582,
      "step": 2325
    },
    {
      "epoch": 0.4130778695728599,
      "grad_norm": 4.687561511993408,
      "learning_rate": 0.00011748989277553172,
      "loss": 0.4125,
      "step": 2350
    },
    {
      "epoch": 0.4174723149938478,
      "grad_norm": 4.757871150970459,
      "learning_rate": 0.00011661100369133416,
      "loss": 0.3865,
      "step": 2375
    },
    {
      "epoch": 0.4218667604148357,
      "grad_norm": 4.543808937072754,
      "learning_rate": 0.00011573211460713658,
      "loss": 0.3826,
      "step": 2400
    },
    {
      "epoch": 0.4262612058358235,
      "grad_norm": 4.884687423706055,
      "learning_rate": 0.00011485322552293901,
      "loss": 0.3838,
      "step": 2425
    },
    {
      "epoch": 0.4306556512568114,
      "grad_norm": 4.4618072509765625,
      "learning_rate": 0.00011397433643874145,
      "loss": 0.371,
      "step": 2450
    },
    {
      "epoch": 0.43505009667779926,
      "grad_norm": 4.025513648986816,
      "learning_rate": 0.00011309544735454387,
      "loss": 0.3757,
      "step": 2475
    },
    {
      "epoch": 0.43944454209878714,
      "grad_norm": 4.078327178955078,
      "learning_rate": 0.00011221655827034629,
      "loss": 0.3635,
      "step": 2500
    },
    {
      "epoch": 0.443838987519775,
      "grad_norm": 5.007492542266846,
      "learning_rate": 0.00011133766918614872,
      "loss": 0.379,
      "step": 2525
    },
    {
      "epoch": 0.4482334329407629,
      "grad_norm": 5.102728366851807,
      "learning_rate": 0.00011045878010195114,
      "loss": 0.3892,
      "step": 2550
    },
    {
      "epoch": 0.4526278783617507,
      "grad_norm": 3.6151037216186523,
      "learning_rate": 0.00010957989101775357,
      "loss": 0.3475,
      "step": 2575
    },
    {
      "epoch": 0.4570223237827386,
      "grad_norm": 3.7705886363983154,
      "learning_rate": 0.00010870100193355599,
      "loss": 0.3606,
      "step": 2600
    },
    {
      "epoch": 0.4614167692037265,
      "grad_norm": 4.968564033508301,
      "learning_rate": 0.00010782211284935841,
      "loss": 0.3548,
      "step": 2625
    },
    {
      "epoch": 0.46581121462471436,
      "grad_norm": 4.564610481262207,
      "learning_rate": 0.00010694322376516084,
      "loss": 0.3886,
      "step": 2650
    },
    {
      "epoch": 0.47020566004570225,
      "grad_norm": 4.895140647888184,
      "learning_rate": 0.00010606433468096326,
      "loss": 0.3694,
      "step": 2675
    },
    {
      "epoch": 0.4746001054666901,
      "grad_norm": 4.261677265167236,
      "learning_rate": 0.00010518544559676568,
      "loss": 0.3681,
      "step": 2700
    },
    {
      "epoch": 0.47899455088767795,
      "grad_norm": 5.429380416870117,
      "learning_rate": 0.00010430655651256811,
      "loss": 0.3586,
      "step": 2725
    },
    {
      "epoch": 0.48338899630866583,
      "grad_norm": 4.1044602394104,
      "learning_rate": 0.00010342766742837053,
      "loss": 0.3558,
      "step": 2750
    },
    {
      "epoch": 0.4877834417296537,
      "grad_norm": 3.33390474319458,
      "learning_rate": 0.00010254877834417298,
      "loss": 0.3358,
      "step": 2775
    },
    {
      "epoch": 0.4921778871506416,
      "grad_norm": 4.690279960632324,
      "learning_rate": 0.00010166988925997541,
      "loss": 0.3473,
      "step": 2800
    },
    {
      "epoch": 0.49657233257162947,
      "grad_norm": 3.861537218093872,
      "learning_rate": 0.00010079100017577783,
      "loss": 0.3837,
      "step": 2825
    },
    {
      "epoch": 0.5009667779926174,
      "grad_norm": 4.353633403778076,
      "learning_rate": 9.991211109158025e-05,
      "loss": 0.3373,
      "step": 2850
    },
    {
      "epoch": 0.5053612234136052,
      "grad_norm": 3.8267366886138916,
      "learning_rate": 9.903322200738268e-05,
      "loss": 0.3597,
      "step": 2875
    },
    {
      "epoch": 0.5097556688345931,
      "grad_norm": 3.9107298851013184,
      "learning_rate": 9.81543329231851e-05,
      "loss": 0.3386,
      "step": 2900
    },
    {
      "epoch": 0.514150114255581,
      "grad_norm": 5.473361015319824,
      "learning_rate": 9.727544383898753e-05,
      "loss": 0.3593,
      "step": 2925
    },
    {
      "epoch": 0.5185445596765689,
      "grad_norm": 4.201390743255615,
      "learning_rate": 9.639655475478995e-05,
      "loss": 0.3377,
      "step": 2950
    },
    {
      "epoch": 0.5229390050975566,
      "grad_norm": 4.690411567687988,
      "learning_rate": 9.551766567059237e-05,
      "loss": 0.3295,
      "step": 2975
    },
    {
      "epoch": 0.5273334505185445,
      "grad_norm": 4.464555740356445,
      "learning_rate": 9.463877658639481e-05,
      "loss": 0.353,
      "step": 3000
    },
    {
      "epoch": 0.5317278959395324,
      "grad_norm": 2.9843101501464844,
      "learning_rate": 9.375988750219723e-05,
      "loss": 0.2937,
      "step": 3025
    },
    {
      "epoch": 0.5361223413605203,
      "grad_norm": 4.5212836265563965,
      "learning_rate": 9.288099841799965e-05,
      "loss": 0.3428,
      "step": 3050
    },
    {
      "epoch": 0.5405167867815082,
      "grad_norm": 4.441213130950928,
      "learning_rate": 9.200210933380208e-05,
      "loss": 0.3139,
      "step": 3075
    },
    {
      "epoch": 0.544911232202496,
      "grad_norm": 3.7290310859680176,
      "learning_rate": 9.11232202496045e-05,
      "loss": 0.3346,
      "step": 3100
    },
    {
      "epoch": 0.5493056776234839,
      "grad_norm": 3.9758739471435547,
      "learning_rate": 9.024433116540693e-05,
      "loss": 0.319,
      "step": 3125
    },
    {
      "epoch": 0.5537001230444718,
      "grad_norm": 5.077330589294434,
      "learning_rate": 8.936544208120936e-05,
      "loss": 0.3665,
      "step": 3150
    },
    {
      "epoch": 0.5580945684654597,
      "grad_norm": 4.511943817138672,
      "learning_rate": 8.848655299701178e-05,
      "loss": 0.3269,
      "step": 3175
    },
    {
      "epoch": 0.5624890138864476,
      "grad_norm": 3.3158490657806396,
      "learning_rate": 8.760766391281421e-05,
      "loss": 0.306,
      "step": 3200
    },
    {
      "epoch": 0.5668834593074354,
      "grad_norm": 4.219069004058838,
      "learning_rate": 8.672877482861663e-05,
      "loss": 0.3404,
      "step": 3225
    },
    {
      "epoch": 0.5712779047284233,
      "grad_norm": 4.44345235824585,
      "learning_rate": 8.584988574441905e-05,
      "loss": 0.3767,
      "step": 3250
    },
    {
      "epoch": 0.5756723501494111,
      "grad_norm": 4.398971080780029,
      "learning_rate": 8.497099666022148e-05,
      "loss": 0.3293,
      "step": 3275
    },
    {
      "epoch": 0.580066795570399,
      "grad_norm": 4.299316883087158,
      "learning_rate": 8.409210757602392e-05,
      "loss": 0.3245,
      "step": 3300
    },
    {
      "epoch": 0.5844612409913869,
      "grad_norm": 3.968243360519409,
      "learning_rate": 8.321321849182633e-05,
      "loss": 0.3347,
      "step": 3325
    },
    {
      "epoch": 0.5888556864123747,
      "grad_norm": 4.579244136810303,
      "learning_rate": 8.233432940762877e-05,
      "loss": 0.3481,
      "step": 3350
    },
    {
      "epoch": 0.5932501318333626,
      "grad_norm": 5.016928195953369,
      "learning_rate": 8.145544032343118e-05,
      "loss": 0.325,
      "step": 3375
    },
    {
      "epoch": 0.5976445772543505,
      "grad_norm": 4.175090789794922,
      "learning_rate": 8.057655123923362e-05,
      "loss": 0.324,
      "step": 3400
    },
    {
      "epoch": 0.6020390226753384,
      "grad_norm": 3.708068370819092,
      "learning_rate": 7.969766215503604e-05,
      "loss": 0.3268,
      "step": 3425
    },
    {
      "epoch": 0.6064334680963263,
      "grad_norm": 3.4974379539489746,
      "learning_rate": 7.881877307083845e-05,
      "loss": 0.3191,
      "step": 3450
    },
    {
      "epoch": 0.6108279135173141,
      "grad_norm": 4.592563629150391,
      "learning_rate": 7.79398839866409e-05,
      "loss": 0.2979,
      "step": 3475
    },
    {
      "epoch": 0.615222358938302,
      "grad_norm": 5.504830837249756,
      "learning_rate": 7.706099490244332e-05,
      "loss": 0.3632,
      "step": 3500
    },
    {
      "epoch": 0.6196168043592899,
      "grad_norm": 4.424801349639893,
      "learning_rate": 7.618210581824574e-05,
      "loss": 0.3141,
      "step": 3525
    },
    {
      "epoch": 0.6240112497802778,
      "grad_norm": 4.740157604217529,
      "learning_rate": 7.530321673404817e-05,
      "loss": 0.3181,
      "step": 3550
    },
    {
      "epoch": 0.6284056952012655,
      "grad_norm": 3.9166066646575928,
      "learning_rate": 7.442432764985059e-05,
      "loss": 0.2982,
      "step": 3575
    },
    {
      "epoch": 0.6328001406222534,
      "grad_norm": 4.033641815185547,
      "learning_rate": 7.354543856565302e-05,
      "loss": 0.3205,
      "step": 3600
    },
    {
      "epoch": 0.6371945860432413,
      "grad_norm": 3.282987356185913,
      "learning_rate": 7.266654948145545e-05,
      "loss": 0.3142,
      "step": 3625
    },
    {
      "epoch": 0.6415890314642292,
      "grad_norm": 4.116844654083252,
      "learning_rate": 7.178766039725787e-05,
      "loss": 0.3172,
      "step": 3650
    },
    {
      "epoch": 0.6459834768852171,
      "grad_norm": 4.023415565490723,
      "learning_rate": 7.09087713130603e-05,
      "loss": 0.3083,
      "step": 3675
    },
    {
      "epoch": 0.650377922306205,
      "grad_norm": 3.929861545562744,
      "learning_rate": 7.002988222886272e-05,
      "loss": 0.3206,
      "step": 3700
    },
    {
      "epoch": 0.6547723677271928,
      "grad_norm": 3.982879161834717,
      "learning_rate": 6.915099314466514e-05,
      "loss": 0.2868,
      "step": 3725
    },
    {
      "epoch": 0.6591668131481807,
      "grad_norm": 3.733409881591797,
      "learning_rate": 6.827210406046757e-05,
      "loss": 0.3032,
      "step": 3750
    },
    {
      "epoch": 0.6635612585691686,
      "grad_norm": 3.9989025592803955,
      "learning_rate": 6.739321497627e-05,
      "loss": 0.3157,
      "step": 3775
    },
    {
      "epoch": 0.6679557039901565,
      "grad_norm": 4.326733112335205,
      "learning_rate": 6.651432589207242e-05,
      "loss": 0.2992,
      "step": 3800
    },
    {
      "epoch": 0.6723501494111443,
      "grad_norm": 3.3516671657562256,
      "learning_rate": 6.563543680787485e-05,
      "loss": 0.2994,
      "step": 3825
    },
    {
      "epoch": 0.6767445948321322,
      "grad_norm": 4.081808090209961,
      "learning_rate": 6.475654772367727e-05,
      "loss": 0.3056,
      "step": 3850
    },
    {
      "epoch": 0.6811390402531201,
      "grad_norm": 3.2005655765533447,
      "learning_rate": 6.387765863947969e-05,
      "loss": 0.3147,
      "step": 3875
    },
    {
      "epoch": 0.6855334856741079,
      "grad_norm": 3.762899160385132,
      "learning_rate": 6.299876955528212e-05,
      "loss": 0.3041,
      "step": 3900
    },
    {
      "epoch": 0.6899279310950958,
      "grad_norm": 3.1652348041534424,
      "learning_rate": 6.211988047108456e-05,
      "loss": 0.3018,
      "step": 3925
    },
    {
      "epoch": 0.6943223765160836,
      "grad_norm": 3.551685333251953,
      "learning_rate": 6.124099138688697e-05,
      "loss": 0.2853,
      "step": 3950
    },
    {
      "epoch": 0.6987168219370715,
      "grad_norm": 2.404815435409546,
      "learning_rate": 6.039725786605731e-05,
      "loss": 0.2767,
      "step": 3975
    },
    {
      "epoch": 0.7031112673580594,
      "grad_norm": 3.701906442642212,
      "learning_rate": 5.9518368781859734e-05,
      "loss": 0.2992,
      "step": 4000
    },
    {
      "epoch": 0.7075057127790473,
      "grad_norm": 3.061608076095581,
      "learning_rate": 5.863947969766216e-05,
      "loss": 0.271,
      "step": 4025
    },
    {
      "epoch": 0.7119001582000352,
      "grad_norm": 4.021250247955322,
      "learning_rate": 5.7760590613464584e-05,
      "loss": 0.3133,
      "step": 4050
    },
    {
      "epoch": 0.716294603621023,
      "grad_norm": 3.575714349746704,
      "learning_rate": 5.688170152926701e-05,
      "loss": 0.2859,
      "step": 4075
    },
    {
      "epoch": 0.7206890490420109,
      "grad_norm": 3.7992403507232666,
      "learning_rate": 5.600281244506943e-05,
      "loss": 0.2947,
      "step": 4100
    },
    {
      "epoch": 0.7250834944629988,
      "grad_norm": 4.031346321105957,
      "learning_rate": 5.512392336087187e-05,
      "loss": 0.2842,
      "step": 4125
    },
    {
      "epoch": 0.7294779398839867,
      "grad_norm": 2.996849298477173,
      "learning_rate": 5.424503427667429e-05,
      "loss": 0.3039,
      "step": 4150
    },
    {
      "epoch": 0.7338723853049746,
      "grad_norm": 2.8503170013427734,
      "learning_rate": 5.336614519247671e-05,
      "loss": 0.3015,
      "step": 4175
    },
    {
      "epoch": 0.7382668307259623,
      "grad_norm": 3.7361972332000732,
      "learning_rate": 5.2487256108279137e-05,
      "loss": 0.3064,
      "step": 4200
    },
    {
      "epoch": 0.7426612761469502,
      "grad_norm": 4.025223255157471,
      "learning_rate": 5.160836702408156e-05,
      "loss": 0.2781,
      "step": 4225
    },
    {
      "epoch": 0.7470557215679381,
      "grad_norm": 2.896561861038208,
      "learning_rate": 5.072947793988399e-05,
      "loss": 0.2812,
      "step": 4250
    },
    {
      "epoch": 0.751450166988926,
      "grad_norm": 3.220350503921509,
      "learning_rate": 4.985058885568641e-05,
      "loss": 0.2815,
      "step": 4275
    },
    {
      "epoch": 0.7558446124099139,
      "grad_norm": 3.9248242378234863,
      "learning_rate": 4.897169977148884e-05,
      "loss": 0.2924,
      "step": 4300
    },
    {
      "epoch": 0.7602390578309017,
      "grad_norm": 3.4190311431884766,
      "learning_rate": 4.809281068729127e-05,
      "loss": 0.2734,
      "step": 4325
    },
    {
      "epoch": 0.7646335032518896,
      "grad_norm": 4.360226631164551,
      "learning_rate": 4.721392160309369e-05,
      "loss": 0.2783,
      "step": 4350
    },
    {
      "epoch": 0.7690279486728775,
      "grad_norm": 3.344046115875244,
      "learning_rate": 4.6335032518896114e-05,
      "loss": 0.2989,
      "step": 4375
    },
    {
      "epoch": 0.7734223940938654,
      "grad_norm": 2.9883882999420166,
      "learning_rate": 4.5456143434698546e-05,
      "loss": 0.2703,
      "step": 4400
    },
    {
      "epoch": 0.7778168395148533,
      "grad_norm": 3.5857608318328857,
      "learning_rate": 4.457725435050097e-05,
      "loss": 0.2837,
      "step": 4425
    },
    {
      "epoch": 0.7822112849358411,
      "grad_norm": 3.126843214035034,
      "learning_rate": 4.369836526630339e-05,
      "loss": 0.2627,
      "step": 4450
    },
    {
      "epoch": 0.786605730356829,
      "grad_norm": 3.9258759021759033,
      "learning_rate": 4.2854631745473723e-05,
      "loss": 0.2914,
      "step": 4475
    },
    {
      "epoch": 0.7910001757778169,
      "grad_norm": 2.7129294872283936,
      "learning_rate": 4.197574266127615e-05,
      "loss": 0.2639,
      "step": 4500
    },
    {
      "epoch": 0.7953946211988047,
      "grad_norm": 3.0593082904815674,
      "learning_rate": 4.1096853577078574e-05,
      "loss": 0.2671,
      "step": 4525
    },
    {
      "epoch": 0.7997890666197925,
      "grad_norm": 4.374273300170898,
      "learning_rate": 4.0217964492881e-05,
      "loss": 0.2816,
      "step": 4550
    },
    {
      "epoch": 0.8041835120407804,
      "grad_norm": 4.358968734741211,
      "learning_rate": 3.9339075408683425e-05,
      "loss": 0.279,
      "step": 4575
    },
    {
      "epoch": 0.8085779574617683,
      "grad_norm": 3.7352700233459473,
      "learning_rate": 3.846018632448585e-05,
      "loss": 0.2791,
      "step": 4600
    },
    {
      "epoch": 0.8129724028827562,
      "grad_norm": 3.438660144805908,
      "learning_rate": 3.7581297240288276e-05,
      "loss": 0.264,
      "step": 4625
    },
    {
      "epoch": 0.8173668483037441,
      "grad_norm": 3.3479957580566406,
      "learning_rate": 3.67024081560907e-05,
      "loss": 0.2711,
      "step": 4650
    },
    {
      "epoch": 0.821761293724732,
      "grad_norm": 2.7979490756988525,
      "learning_rate": 3.582351907189313e-05,
      "loss": 0.2729,
      "step": 4675
    },
    {
      "epoch": 0.8261557391457198,
      "grad_norm": 3.1490190029144287,
      "learning_rate": 3.494462998769555e-05,
      "loss": 0.2624,
      "step": 4700
    },
    {
      "epoch": 0.8305501845667077,
      "grad_norm": 3.985703706741333,
      "learning_rate": 3.406574090349798e-05,
      "loss": 0.2741,
      "step": 4725
    },
    {
      "epoch": 0.8349446299876956,
      "grad_norm": 4.66172456741333,
      "learning_rate": 3.318685181930041e-05,
      "loss": 0.2865,
      "step": 4750
    },
    {
      "epoch": 0.8393390754086835,
      "grad_norm": 4.1256537437438965,
      "learning_rate": 3.2307962735102835e-05,
      "loss": 0.2933,
      "step": 4775
    },
    {
      "epoch": 0.8437335208296713,
      "grad_norm": 2.443140983581543,
      "learning_rate": 3.142907365090525e-05,
      "loss": 0.2495,
      "step": 4800
    },
    {
      "epoch": 0.8481279662506591,
      "grad_norm": 3.501038074493408,
      "learning_rate": 3.0550184566707685e-05,
      "loss": 0.2578,
      "step": 4825
    },
    {
      "epoch": 0.852522411671647,
      "grad_norm": 2.979487895965576,
      "learning_rate": 2.9671295482510107e-05,
      "loss": 0.2594,
      "step": 4850
    },
    {
      "epoch": 0.8569168570926349,
      "grad_norm": 2.1413772106170654,
      "learning_rate": 2.8792406398312533e-05,
      "loss": 0.2751,
      "step": 4875
    },
    {
      "epoch": 0.8613113025136228,
      "grad_norm": 4.424350738525391,
      "learning_rate": 2.791351731411496e-05,
      "loss": 0.2747,
      "step": 4900
    },
    {
      "epoch": 0.8657057479346106,
      "grad_norm": 4.2690887451171875,
      "learning_rate": 2.7034628229917387e-05,
      "loss": 0.2574,
      "step": 4925
    },
    {
      "epoch": 0.8701001933555985,
      "grad_norm": 3.3833954334259033,
      "learning_rate": 2.615573914571981e-05,
      "loss": 0.2765,
      "step": 4950
    },
    {
      "epoch": 0.8744946387765864,
      "grad_norm": 3.8899686336517334,
      "learning_rate": 2.527685006152224e-05,
      "loss": 0.2584,
      "step": 4975
    },
    {
      "epoch": 0.8788890841975743,
      "grad_norm": 3.754274368286133,
      "learning_rate": 2.4397960977324663e-05,
      "loss": 0.2787,
      "step": 5000
    },
    {
      "epoch": 0.8832835296185622,
      "grad_norm": 2.6849217414855957,
      "learning_rate": 2.3519071893127088e-05,
      "loss": 0.2723,
      "step": 5025
    },
    {
      "epoch": 0.88767797503955,
      "grad_norm": 3.3370320796966553,
      "learning_rate": 2.2640182808929514e-05,
      "loss": 0.2567,
      "step": 5050
    },
    {
      "epoch": 0.8920724204605379,
      "grad_norm": 3.1560068130493164,
      "learning_rate": 2.176129372473194e-05,
      "loss": 0.2685,
      "step": 5075
    },
    {
      "epoch": 0.8964668658815258,
      "grad_norm": 2.6506128311157227,
      "learning_rate": 2.0882404640534364e-05,
      "loss": 0.248,
      "step": 5100
    },
    {
      "epoch": 0.9008613113025136,
      "grad_norm": 3.814223527908325,
      "learning_rate": 2.000351555633679e-05,
      "loss": 0.2696,
      "step": 5125
    },
    {
      "epoch": 0.9052557567235014,
      "grad_norm": 1.7542328834533691,
      "learning_rate": 1.912462647213922e-05,
      "loss": 0.256,
      "step": 5150
    },
    {
      "epoch": 0.9096502021444893,
      "grad_norm": 4.168238639831543,
      "learning_rate": 1.824573738794164e-05,
      "loss": 0.2624,
      "step": 5175
    },
    {
      "epoch": 0.9140446475654772,
      "grad_norm": 3.671499013900757,
      "learning_rate": 1.736684830374407e-05,
      "loss": 0.2721,
      "step": 5200
    },
    {
      "epoch": 0.9184390929864651,
      "grad_norm": 3.3060355186462402,
      "learning_rate": 1.6487959219546495e-05,
      "loss": 0.2366,
      "step": 5225
    },
    {
      "epoch": 0.922833538407453,
      "grad_norm": 2.5487847328186035,
      "learning_rate": 1.560907013534892e-05,
      "loss": 0.255,
      "step": 5250
    },
    {
      "epoch": 0.9272279838284408,
      "grad_norm": 2.9597721099853516,
      "learning_rate": 1.4730181051151345e-05,
      "loss": 0.2419,
      "step": 5275
    },
    {
      "epoch": 0.9316224292494287,
      "grad_norm": 2.3521227836608887,
      "learning_rate": 1.3851291966953772e-05,
      "loss": 0.2523,
      "step": 5300
    },
    {
      "epoch": 0.9360168746704166,
      "grad_norm": 3.5430359840393066,
      "learning_rate": 1.2972402882756196e-05,
      "loss": 0.2496,
      "step": 5325
    },
    {
      "epoch": 0.9404113200914045,
      "grad_norm": 4.03538703918457,
      "learning_rate": 1.2093513798558623e-05,
      "loss": 0.2802,
      "step": 5350
    },
    {
      "epoch": 0.9448057655123924,
      "grad_norm": 3.945798873901367,
      "learning_rate": 1.1214624714361048e-05,
      "loss": 0.2515,
      "step": 5375
    },
    {
      "epoch": 0.9492002109333803,
      "grad_norm": 4.295114994049072,
      "learning_rate": 1.0335735630163474e-05,
      "loss": 0.2798,
      "step": 5400
    },
    {
      "epoch": 0.9535946563543681,
      "grad_norm": 3.3008806705474854,
      "learning_rate": 9.4568465459659e-06,
      "loss": 0.2701,
      "step": 5425
    },
    {
      "epoch": 0.9579891017753559,
      "grad_norm": 3.069348096847534,
      "learning_rate": 8.577957461768325e-06,
      "loss": 0.2486,
      "step": 5450
    },
    {
      "epoch": 0.9623835471963438,
      "grad_norm": 3.1481006145477295,
      "learning_rate": 7.69906837757075e-06,
      "loss": 0.2573,
      "step": 5475
    },
    {
      "epoch": 0.9667779926173317,
      "grad_norm": 3.9434046745300293,
      "learning_rate": 6.820179293373177e-06,
      "loss": 0.2803,
      "step": 5500
    },
    {
      "epoch": 0.9711724380383195,
      "grad_norm": 2.616339921951294,
      "learning_rate": 5.941290209175602e-06,
      "loss": 0.2658,
      "step": 5525
    },
    {
      "epoch": 0.9755668834593074,
      "grad_norm": 1.9436520338058472,
      "learning_rate": 5.062401124978028e-06,
      "loss": 0.2503,
      "step": 5550
    },
    {
      "epoch": 0.9799613288802953,
      "grad_norm": 2.2040159702301025,
      "learning_rate": 4.183512040780454e-06,
      "loss": 0.2605,
      "step": 5575
    },
    {
      "epoch": 0.9843557743012832,
      "grad_norm": 3.591538906097412,
      "learning_rate": 3.3046229565828793e-06,
      "loss": 0.2802,
      "step": 5600
    },
    {
      "epoch": 0.9887502197222711,
      "grad_norm": 3.265550374984741,
      "learning_rate": 2.425733872385305e-06,
      "loss": 0.2768,
      "step": 5625
    },
    {
      "epoch": 0.9931446651432589,
      "grad_norm": 2.259087085723877,
      "learning_rate": 1.5468447881877309e-06,
      "loss": 0.2671,
      "step": 5650
    },
    {
      "epoch": 0.9975391105642468,
      "grad_norm": 3.062272071838379,
      "learning_rate": 6.679557039901565e-07,
      "loss": 0.2633,
      "step": 5675
    }
  ],
  "logging_steps": 25,
  "max_steps": 5689,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.950561664573112e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
