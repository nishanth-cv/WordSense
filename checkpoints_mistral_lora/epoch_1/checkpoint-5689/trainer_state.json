{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5689,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004394445420987872,
      "grad_norm": 1.6959537267684937,
      "learning_rate": 0.00019915626647917033,
      "loss": 1.7675,
      "step": 25
    },
    {
      "epoch": 0.008788890841975743,
      "grad_norm": 1.5778846740722656,
      "learning_rate": 0.00019827737739497276,
      "loss": 1.6582,
      "step": 50
    },
    {
      "epoch": 0.013183336262963615,
      "grad_norm": 1.788078784942627,
      "learning_rate": 0.0001973984883107752,
      "loss": 1.6805,
      "step": 75
    },
    {
      "epoch": 0.017577781683951486,
      "grad_norm": 2.274937868118286,
      "learning_rate": 0.0001965195992265776,
      "loss": 1.8116,
      "step": 100
    },
    {
      "epoch": 0.021972227104939356,
      "grad_norm": 1.7049959897994995,
      "learning_rate": 0.00019564071014238003,
      "loss": 1.7385,
      "step": 125
    },
    {
      "epoch": 0.02636667252592723,
      "grad_norm": 1.618272304534912,
      "learning_rate": 0.00019476182105818246,
      "loss": 1.7131,
      "step": 150
    },
    {
      "epoch": 0.0307611179469151,
      "grad_norm": 2.801938056945801,
      "learning_rate": 0.0001938829319739849,
      "loss": 1.6707,
      "step": 175
    },
    {
      "epoch": 0.03515556336790297,
      "grad_norm": 2.17629337310791,
      "learning_rate": 0.00019300404288978733,
      "loss": 1.6587,
      "step": 200
    },
    {
      "epoch": 0.03955000878889084,
      "grad_norm": 1.8864272832870483,
      "learning_rate": 0.00019212515380558976,
      "loss": 1.6542,
      "step": 225
    },
    {
      "epoch": 0.04394445420987871,
      "grad_norm": 2.3460304737091064,
      "learning_rate": 0.00019124626472139216,
      "loss": 1.6813,
      "step": 250
    },
    {
      "epoch": 0.048338899630866586,
      "grad_norm": 1.7388687133789062,
      "learning_rate": 0.0001903673756371946,
      "loss": 1.6815,
      "step": 275
    },
    {
      "epoch": 0.05273334505185446,
      "grad_norm": NaN,
      "learning_rate": 0.00018948848655299703,
      "loss": 1.5853,
      "step": 300
    },
    {
      "epoch": 0.057127790472842326,
      "grad_norm": 1.7839750051498413,
      "learning_rate": 0.00018864475303216735,
      "loss": 1.61,
      "step": 325
    },
    {
      "epoch": 0.0615222358938302,
      "grad_norm": 1.5330612659454346,
      "learning_rate": 0.00018776586394796978,
      "loss": 1.6007,
      "step": 350
    },
    {
      "epoch": 0.06591668131481807,
      "grad_norm": 2.403390407562256,
      "learning_rate": 0.0001868869748637722,
      "loss": 1.5645,
      "step": 375
    },
    {
      "epoch": 0.07031112673580595,
      "grad_norm": 1.7344034910202026,
      "learning_rate": 0.00018600808577957462,
      "loss": 1.5619,
      "step": 400
    },
    {
      "epoch": 0.07470557215679381,
      "grad_norm": 2.325853109359741,
      "learning_rate": 0.00018512919669537705,
      "loss": 1.5601,
      "step": 425
    },
    {
      "epoch": 0.07910001757778168,
      "grad_norm": 1.9405171871185303,
      "learning_rate": 0.00018425030761117948,
      "loss": 1.536,
      "step": 450
    },
    {
      "epoch": 0.08349446299876956,
      "grad_norm": 1.851410984992981,
      "learning_rate": 0.0001833714185269819,
      "loss": 1.5046,
      "step": 475
    },
    {
      "epoch": 0.08788890841975742,
      "grad_norm": 2.3198609352111816,
      "learning_rate": 0.00018249252944278432,
      "loss": 1.5332,
      "step": 500
    },
    {
      "epoch": 0.09228335384074529,
      "grad_norm": 2.19712495803833,
      "learning_rate": 0.00018161364035858675,
      "loss": 1.4736,
      "step": 525
    },
    {
      "epoch": 0.09667779926173317,
      "grad_norm": 1.8792734146118164,
      "learning_rate": 0.00018073475127438918,
      "loss": 1.4682,
      "step": 550
    },
    {
      "epoch": 0.10107224468272104,
      "grad_norm": 2.1414430141448975,
      "learning_rate": 0.00017985586219019162,
      "loss": 1.5018,
      "step": 575
    },
    {
      "epoch": 0.10546669010370892,
      "grad_norm": 1.9705135822296143,
      "learning_rate": 0.00017897697310599405,
      "loss": 1.4752,
      "step": 600
    },
    {
      "epoch": 0.10986113552469678,
      "grad_norm": 2.109079360961914,
      "learning_rate": 0.00017809808402179645,
      "loss": 1.4122,
      "step": 625
    },
    {
      "epoch": 0.11425558094568465,
      "grad_norm": 2.0968198776245117,
      "learning_rate": 0.00017721919493759888,
      "loss": 1.4194,
      "step": 650
    },
    {
      "epoch": 0.11865002636667253,
      "grad_norm": 2.463545083999634,
      "learning_rate": 0.00017634030585340132,
      "loss": 1.4694,
      "step": 675
    },
    {
      "epoch": 0.1230444717876604,
      "grad_norm": 2.4905333518981934,
      "learning_rate": 0.00017549657233257164,
      "loss": 1.3953,
      "step": 700
    },
    {
      "epoch": 0.12743891720864828,
      "grad_norm": 2.2838149070739746,
      "learning_rate": 0.00017461768324837407,
      "loss": 1.4387,
      "step": 725
    },
    {
      "epoch": 0.13183336262963613,
      "grad_norm": 2.7645254135131836,
      "learning_rate": 0.0001737387941641765,
      "loss": 1.3016,
      "step": 750
    },
    {
      "epoch": 0.136227808050624,
      "grad_norm": 6.0269598960876465,
      "learning_rate": 0.0001728599050799789,
      "loss": 1.3804,
      "step": 775
    },
    {
      "epoch": 0.1406222534716119,
      "grad_norm": 2.1795647144317627,
      "learning_rate": 0.00017198101599578134,
      "loss": 1.3624,
      "step": 800
    },
    {
      "epoch": 0.14501669889259974,
      "grad_norm": 2.85481595993042,
      "learning_rate": 0.00017110212691158377,
      "loss": 1.3678,
      "step": 825
    },
    {
      "epoch": 0.14941114431358762,
      "grad_norm": 2.437101364135742,
      "learning_rate": 0.00017022323782738618,
      "loss": 1.3492,
      "step": 850
    },
    {
      "epoch": 0.1538055897345755,
      "grad_norm": 3.072622776031494,
      "learning_rate": 0.0001693443487431886,
      "loss": 1.341,
      "step": 875
    },
    {
      "epoch": 0.15820003515556336,
      "grad_norm": 2.3891212940216064,
      "learning_rate": 0.00016846545965899107,
      "loss": 1.2633,
      "step": 900
    },
    {
      "epoch": 0.16259448057655124,
      "grad_norm": 3.0996224880218506,
      "learning_rate": 0.00016758657057479347,
      "loss": 1.2943,
      "step": 925
    },
    {
      "epoch": 0.16698892599753912,
      "grad_norm": 2.8205487728118896,
      "learning_rate": 0.0001667076814905959,
      "loss": 1.2705,
      "step": 950
    },
    {
      "epoch": 0.17138337141852697,
      "grad_norm": 2.9580085277557373,
      "learning_rate": 0.00016582879240639834,
      "loss": 1.2531,
      "step": 975
    },
    {
      "epoch": 0.17577781683951485,
      "grad_norm": 3.0108227729797363,
      "learning_rate": 0.00016494990332220074,
      "loss": 1.2541,
      "step": 1000
    },
    {
      "epoch": 0.18017226226050273,
      "grad_norm": 2.6281473636627197,
      "learning_rate": 0.00016407101423800317,
      "loss": 1.1907,
      "step": 1025
    },
    {
      "epoch": 0.18456670768149058,
      "grad_norm": 3.123823642730713,
      "learning_rate": 0.0001631921251538056,
      "loss": 1.2445,
      "step": 1050
    },
    {
      "epoch": 0.18896115310247846,
      "grad_norm": 3.059718132019043,
      "learning_rate": 0.000162313236069608,
      "loss": 1.2371,
      "step": 1075
    },
    {
      "epoch": 0.19335559852346634,
      "grad_norm": 3.263307571411133,
      "learning_rate": 0.00016143434698541044,
      "loss": 1.2649,
      "step": 1100
    },
    {
      "epoch": 0.19775004394445422,
      "grad_norm": 3.258744478225708,
      "learning_rate": 0.00016055545790121287,
      "loss": 1.2459,
      "step": 1125
    },
    {
      "epoch": 0.20214448936544208,
      "grad_norm": 3.112363576889038,
      "learning_rate": 0.00015967656881701528,
      "loss": 1.176,
      "step": 1150
    },
    {
      "epoch": 0.20653893478642996,
      "grad_norm": 4.297112941741943,
      "learning_rate": 0.0001587976797328177,
      "loss": 1.1657,
      "step": 1175
    },
    {
      "epoch": 0.21093338020741784,
      "grad_norm": 5.37678861618042,
      "learning_rate": 0.00015791879064862014,
      "loss": 1.1155,
      "step": 1200
    },
    {
      "epoch": 0.2153278256284057,
      "grad_norm": 3.6055240631103516,
      "learning_rate": 0.00015703990156442258,
      "loss": 1.1576,
      "step": 1225
    },
    {
      "epoch": 0.21972227104939357,
      "grad_norm": 3.1702191829681396,
      "learning_rate": 0.000156161012480225,
      "loss": 1.1641,
      "step": 1250
    },
    {
      "epoch": 0.22411671647038145,
      "grad_norm": 3.1266705989837646,
      "learning_rate": 0.00015528212339602744,
      "loss": 1.1199,
      "step": 1275
    },
    {
      "epoch": 0.2285111618913693,
      "grad_norm": 3.3904595375061035,
      "learning_rate": 0.00015440323431182985,
      "loss": 1.1479,
      "step": 1300
    },
    {
      "epoch": 0.23290560731235718,
      "grad_norm": 2.8831660747528076,
      "learning_rate": 0.00015352434522763228,
      "loss": 1.1124,
      "step": 1325
    },
    {
      "epoch": 0.23730005273334506,
      "grad_norm": 3.217362403869629,
      "learning_rate": 0.0001526454561434347,
      "loss": 1.0909,
      "step": 1350
    },
    {
      "epoch": 0.24169449815433292,
      "grad_norm": 2.913701057434082,
      "learning_rate": 0.00015176656705923714,
      "loss": 1.1204,
      "step": 1375
    },
    {
      "epoch": 0.2460889435753208,
      "grad_norm": 3.269784927368164,
      "learning_rate": 0.00015088767797503955,
      "loss": 1.1511,
      "step": 1400
    },
    {
      "epoch": 0.2504833889963087,
      "grad_norm": 4.3073906898498535,
      "learning_rate": 0.00015000878889084198,
      "loss": 1.0672,
      "step": 1425
    },
    {
      "epoch": 0.25487783441729656,
      "grad_norm": 3.534428358078003,
      "learning_rate": 0.0001491298998066444,
      "loss": 1.0956,
      "step": 1450
    },
    {
      "epoch": 0.25927227983828444,
      "grad_norm": 3.35286808013916,
      "learning_rate": 0.00014825101072244682,
      "loss": 1.125,
      "step": 1475
    },
    {
      "epoch": 0.26366672525927226,
      "grad_norm": 3.536672353744507,
      "learning_rate": 0.00014737212163824925,
      "loss": 1.0457,
      "step": 1500
    },
    {
      "epoch": 0.26806117068026014,
      "grad_norm": 3.8629262447357178,
      "learning_rate": 0.0001464932325540517,
      "loss": 1.0854,
      "step": 1525
    },
    {
      "epoch": 0.272455616101248,
      "grad_norm": 3.627671957015991,
      "learning_rate": 0.0001456143434698541,
      "loss": 1.0575,
      "step": 1550
    },
    {
      "epoch": 0.2768500615222359,
      "grad_norm": 3.851306438446045,
      "learning_rate": 0.00014473545438565654,
      "loss": 1.0455,
      "step": 1575
    },
    {
      "epoch": 0.2812445069432238,
      "grad_norm": 3.447526693344116,
      "learning_rate": 0.00014385656530145898,
      "loss": 1.0045,
      "step": 1600
    },
    {
      "epoch": 0.28563895236421166,
      "grad_norm": 3.347024917602539,
      "learning_rate": 0.00014297767621726138,
      "loss": 1.0115,
      "step": 1625
    },
    {
      "epoch": 0.2900333977851995,
      "grad_norm": 4.045755863189697,
      "learning_rate": 0.00014209878713306381,
      "loss": 1.004,
      "step": 1650
    },
    {
      "epoch": 0.29442784320618737,
      "grad_norm": 3.5474650859832764,
      "learning_rate": 0.00014121989804886625,
      "loss": 1.0044,
      "step": 1675
    },
    {
      "epoch": 0.29882228862717525,
      "grad_norm": 4.038934230804443,
      "learning_rate": 0.00014034100896466865,
      "loss": 1.0198,
      "step": 1700
    },
    {
      "epoch": 0.30321673404816313,
      "grad_norm": 3.7614502906799316,
      "learning_rate": 0.00013946211988047108,
      "loss": 0.9966,
      "step": 1725
    },
    {
      "epoch": 0.307611179469151,
      "grad_norm": 3.7158658504486084,
      "learning_rate": 0.00013858323079627352,
      "loss": 0.9408,
      "step": 1750
    },
    {
      "epoch": 0.3120056248901389,
      "grad_norm": 3.504586935043335,
      "learning_rate": 0.00013770434171207595,
      "loss": 0.9965,
      "step": 1775
    },
    {
      "epoch": 0.3164000703111267,
      "grad_norm": 3.075380563735962,
      "learning_rate": 0.00013682545262787835,
      "loss": 0.9844,
      "step": 1800
    },
    {
      "epoch": 0.3207945157321146,
      "grad_norm": 4.027832508087158,
      "learning_rate": 0.0001359465635436808,
      "loss": 0.9353,
      "step": 1825
    },
    {
      "epoch": 0.3251889611531025,
      "grad_norm": 3.704423666000366,
      "learning_rate": 0.00013506767445948322,
      "loss": 0.9629,
      "step": 1850
    },
    {
      "epoch": 0.32958340657409035,
      "grad_norm": 4.5524115562438965,
      "learning_rate": 0.00013418878537528565,
      "loss": 0.9243,
      "step": 1875
    },
    {
      "epoch": 0.33397785199507823,
      "grad_norm": 4.189158916473389,
      "learning_rate": 0.00013330989629108808,
      "loss": 0.9604,
      "step": 1900
    },
    {
      "epoch": 0.3383722974160661,
      "grad_norm": 3.9217827320098877,
      "learning_rate": 0.0001324310072068905,
      "loss": 0.9451,
      "step": 1925
    },
    {
      "epoch": 0.34276674283705394,
      "grad_norm": 4.100826740264893,
      "learning_rate": 0.00013155211812269292,
      "loss": 0.9323,
      "step": 1950
    },
    {
      "epoch": 0.3471611882580418,
      "grad_norm": 4.741532325744629,
      "learning_rate": 0.00013067322903849535,
      "loss": 0.947,
      "step": 1975
    },
    {
      "epoch": 0.3515556336790297,
      "grad_norm": 3.8650548458099365,
      "learning_rate": 0.00012979433995429778,
      "loss": 0.9382,
      "step": 2000
    },
    {
      "epoch": 0.3559500791000176,
      "grad_norm": 4.474979400634766,
      "learning_rate": 0.0001289154508701002,
      "loss": 0.9114,
      "step": 2025
    },
    {
      "epoch": 0.36034452452100546,
      "grad_norm": 3.876812219619751,
      "learning_rate": 0.00012803656178590262,
      "loss": 0.8652,
      "step": 2050
    },
    {
      "epoch": 0.36473896994199334,
      "grad_norm": 3.442626714706421,
      "learning_rate": 0.00012715767270170505,
      "loss": 0.8619,
      "step": 2075
    },
    {
      "epoch": 0.36913341536298117,
      "grad_norm": 3.7925291061401367,
      "learning_rate": 0.00012627878361750746,
      "loss": 0.864,
      "step": 2100
    },
    {
      "epoch": 0.37352786078396905,
      "grad_norm": 3.9973998069763184,
      "learning_rate": 0.0001253998945333099,
      "loss": 0.8213,
      "step": 2125
    },
    {
      "epoch": 0.3779223062049569,
      "grad_norm": 3.2260327339172363,
      "learning_rate": 0.00012452100544911235,
      "loss": 0.8558,
      "step": 2150
    },
    {
      "epoch": 0.3823167516259448,
      "grad_norm": 4.119714260101318,
      "learning_rate": 0.00012364211636491475,
      "loss": 0.8174,
      "step": 2175
    },
    {
      "epoch": 0.3867111970469327,
      "grad_norm": 4.398602485656738,
      "learning_rate": 0.00012276322728071719,
      "loss": 0.8643,
      "step": 2200
    },
    {
      "epoch": 0.39110564246792057,
      "grad_norm": 4.346430778503418,
      "learning_rate": 0.0001218843381965196,
      "loss": 0.8042,
      "step": 2225
    },
    {
      "epoch": 0.39550008788890845,
      "grad_norm": 5.195128917694092,
      "learning_rate": 0.00012100544911232204,
      "loss": 0.8121,
      "step": 2250
    },
    {
      "epoch": 0.39989453330989627,
      "grad_norm": 4.786737442016602,
      "learning_rate": 0.00012012656002812446,
      "loss": 0.8384,
      "step": 2275
    },
    {
      "epoch": 0.40428897873088415,
      "grad_norm": 4.753098487854004,
      "learning_rate": 0.00011924767094392689,
      "loss": 0.8438,
      "step": 2300
    },
    {
      "epoch": 0.40868342415187203,
      "grad_norm": 5.99085807800293,
      "learning_rate": 0.0001183687818597293,
      "loss": 0.7696,
      "step": 2325
    },
    {
      "epoch": 0.4130778695728599,
      "grad_norm": 4.0908589363098145,
      "learning_rate": 0.00011748989277553172,
      "loss": 0.8756,
      "step": 2350
    },
    {
      "epoch": 0.4174723149938478,
      "grad_norm": 3.9063847064971924,
      "learning_rate": 0.00011661100369133416,
      "loss": 0.8071,
      "step": 2375
    },
    {
      "epoch": 0.4218667604148357,
      "grad_norm": 5.058690071105957,
      "learning_rate": 0.00011573211460713658,
      "loss": 0.805,
      "step": 2400
    },
    {
      "epoch": 0.4262612058358235,
      "grad_norm": 4.370926856994629,
      "learning_rate": 0.00011485322552293901,
      "loss": 0.7857,
      "step": 2425
    },
    {
      "epoch": 0.4306556512568114,
      "grad_norm": 4.154585361480713,
      "learning_rate": 0.00011397433643874145,
      "loss": 0.7678,
      "step": 2450
    },
    {
      "epoch": 0.43505009667779926,
      "grad_norm": 4.195135116577148,
      "learning_rate": 0.00011309544735454387,
      "loss": 0.7675,
      "step": 2475
    },
    {
      "epoch": 0.43944454209878714,
      "grad_norm": 5.261968612670898,
      "learning_rate": 0.00011221655827034629,
      "loss": 0.766,
      "step": 2500
    },
    {
      "epoch": 0.443838987519775,
      "grad_norm": 5.124390125274658,
      "learning_rate": 0.00011133766918614872,
      "loss": 0.8047,
      "step": 2525
    },
    {
      "epoch": 0.4482334329407629,
      "grad_norm": 5.741182327270508,
      "learning_rate": 0.00011045878010195114,
      "loss": 0.7803,
      "step": 2550
    },
    {
      "epoch": 0.4526278783617507,
      "grad_norm": 4.471554279327393,
      "learning_rate": 0.00010957989101775357,
      "loss": 0.7406,
      "step": 2575
    },
    {
      "epoch": 0.4570223237827386,
      "grad_norm": 3.607707977294922,
      "learning_rate": 0.00010870100193355599,
      "loss": 0.7675,
      "step": 2600
    },
    {
      "epoch": 0.4614167692037265,
      "grad_norm": 4.830097675323486,
      "learning_rate": 0.00010782211284935841,
      "loss": 0.7399,
      "step": 2625
    },
    {
      "epoch": 0.46581121462471436,
      "grad_norm": 4.780245780944824,
      "learning_rate": 0.00010694322376516084,
      "loss": 0.7656,
      "step": 2650
    },
    {
      "epoch": 0.47020566004570225,
      "grad_norm": 4.801891803741455,
      "learning_rate": 0.00010606433468096326,
      "loss": 0.7419,
      "step": 2675
    },
    {
      "epoch": 0.4746001054666901,
      "grad_norm": 3.93117094039917,
      "learning_rate": 0.00010518544559676568,
      "loss": 0.7366,
      "step": 2700
    },
    {
      "epoch": 0.47899455088767795,
      "grad_norm": 5.2909321784973145,
      "learning_rate": 0.00010430655651256811,
      "loss": 0.7209,
      "step": 2725
    },
    {
      "epoch": 0.48338899630866583,
      "grad_norm": 4.796542167663574,
      "learning_rate": 0.00010342766742837053,
      "loss": 0.7162,
      "step": 2750
    },
    {
      "epoch": 0.4877834417296537,
      "grad_norm": 3.8112547397613525,
      "learning_rate": 0.00010254877834417298,
      "loss": 0.698,
      "step": 2775
    },
    {
      "epoch": 0.4921778871506416,
      "grad_norm": 5.172453880310059,
      "learning_rate": 0.00010166988925997541,
      "loss": 0.6791,
      "step": 2800
    },
    {
      "epoch": 0.49657233257162947,
      "grad_norm": 4.402004241943359,
      "learning_rate": 0.00010079100017577783,
      "loss": 0.7718,
      "step": 2825
    },
    {
      "epoch": 0.5009667779926174,
      "grad_norm": 3.972163438796997,
      "learning_rate": 9.991211109158025e-05,
      "loss": 0.6666,
      "step": 2850
    },
    {
      "epoch": 0.5053612234136052,
      "grad_norm": 4.409719944000244,
      "learning_rate": 9.903322200738268e-05,
      "loss": 0.7171,
      "step": 2875
    },
    {
      "epoch": 0.5097556688345931,
      "grad_norm": 3.994100570678711,
      "learning_rate": 9.81543329231851e-05,
      "loss": 0.6785,
      "step": 2900
    },
    {
      "epoch": 0.514150114255581,
      "grad_norm": 5.297416687011719,
      "learning_rate": 9.727544383898753e-05,
      "loss": 0.7217,
      "step": 2925
    },
    {
      "epoch": 0.5185445596765689,
      "grad_norm": 6.1425018310546875,
      "learning_rate": 9.639655475478995e-05,
      "loss": 0.673,
      "step": 2950
    },
    {
      "epoch": 0.5229390050975566,
      "grad_norm": 4.698758125305176,
      "learning_rate": 9.551766567059237e-05,
      "loss": 0.6457,
      "step": 2975
    },
    {
      "epoch": 0.5273334505185445,
      "grad_norm": 4.756786346435547,
      "learning_rate": 9.463877658639481e-05,
      "loss": 0.6862,
      "step": 3000
    },
    {
      "epoch": 0.5317278959395324,
      "grad_norm": 4.141385555267334,
      "learning_rate": 9.375988750219723e-05,
      "loss": 0.6009,
      "step": 3025
    },
    {
      "epoch": 0.5361223413605203,
      "grad_norm": 3.712780714035034,
      "learning_rate": 9.288099841799965e-05,
      "loss": 0.6863,
      "step": 3050
    },
    {
      "epoch": 0.5405167867815082,
      "grad_norm": 5.264293670654297,
      "learning_rate": 9.200210933380208e-05,
      "loss": 0.6289,
      "step": 3075
    },
    {
      "epoch": 0.544911232202496,
      "grad_norm": 4.262485504150391,
      "learning_rate": 9.11232202496045e-05,
      "loss": 0.6511,
      "step": 3100
    },
    {
      "epoch": 0.5493056776234839,
      "grad_norm": 4.873604774475098,
      "learning_rate": 9.024433116540693e-05,
      "loss": 0.6204,
      "step": 3125
    },
    {
      "epoch": 0.5537001230444718,
      "grad_norm": 5.236302375793457,
      "learning_rate": 8.936544208120936e-05,
      "loss": 0.6791,
      "step": 3150
    },
    {
      "epoch": 0.5580945684654597,
      "grad_norm": 4.240631103515625,
      "learning_rate": 8.848655299701178e-05,
      "loss": 0.6431,
      "step": 3175
    },
    {
      "epoch": 0.5624890138864476,
      "grad_norm": 3.9530861377716064,
      "learning_rate": 8.760766391281421e-05,
      "loss": 0.5931,
      "step": 3200
    },
    {
      "epoch": 0.5668834593074354,
      "grad_norm": 6.062689304351807,
      "learning_rate": 8.672877482861663e-05,
      "loss": 0.6314,
      "step": 3225
    },
    {
      "epoch": 0.5712779047284233,
      "grad_norm": 5.329077243804932,
      "learning_rate": 8.584988574441905e-05,
      "loss": 0.6845,
      "step": 3250
    },
    {
      "epoch": 0.5756723501494111,
      "grad_norm": 5.148834228515625,
      "learning_rate": 8.497099666022148e-05,
      "loss": 0.6481,
      "step": 3275
    },
    {
      "epoch": 0.580066795570399,
      "grad_norm": 4.242053508758545,
      "learning_rate": 8.409210757602392e-05,
      "loss": 0.6115,
      "step": 3300
    },
    {
      "epoch": 0.5844612409913869,
      "grad_norm": 4.487554550170898,
      "learning_rate": 8.321321849182633e-05,
      "loss": 0.6329,
      "step": 3325
    },
    {
      "epoch": 0.5888556864123747,
      "grad_norm": 4.269248008728027,
      "learning_rate": 8.233432940762877e-05,
      "loss": 0.6552,
      "step": 3350
    },
    {
      "epoch": 0.5932501318333626,
      "grad_norm": 5.7689595222473145,
      "learning_rate": 8.145544032343118e-05,
      "loss": 0.6199,
      "step": 3375
    },
    {
      "epoch": 0.5976445772543505,
      "grad_norm": 4.869911193847656,
      "learning_rate": 8.057655123923362e-05,
      "loss": 0.6146,
      "step": 3400
    },
    {
      "epoch": 0.6020390226753384,
      "grad_norm": 4.187714576721191,
      "learning_rate": 7.969766215503604e-05,
      "loss": 0.6146,
      "step": 3425
    },
    {
      "epoch": 0.6064334680963263,
      "grad_norm": 4.19066858291626,
      "learning_rate": 7.881877307083845e-05,
      "loss": 0.5921,
      "step": 3450
    },
    {
      "epoch": 0.6108279135173141,
      "grad_norm": 4.7735371589660645,
      "learning_rate": 7.79398839866409e-05,
      "loss": 0.5722,
      "step": 3475
    },
    {
      "epoch": 0.615222358938302,
      "grad_norm": 5.209989547729492,
      "learning_rate": 7.706099490244332e-05,
      "loss": 0.647,
      "step": 3500
    },
    {
      "epoch": 0.6196168043592899,
      "grad_norm": 4.8080363273620605,
      "learning_rate": 7.618210581824574e-05,
      "loss": 0.5973,
      "step": 3525
    },
    {
      "epoch": 0.6240112497802778,
      "grad_norm": 5.265746116638184,
      "learning_rate": 7.530321673404817e-05,
      "loss": 0.6039,
      "step": 3550
    },
    {
      "epoch": 0.6284056952012655,
      "grad_norm": 5.511417388916016,
      "learning_rate": 7.442432764985059e-05,
      "loss": 0.5531,
      "step": 3575
    },
    {
      "epoch": 0.6328001406222534,
      "grad_norm": 4.155630588531494,
      "learning_rate": 7.354543856565302e-05,
      "loss": 0.5908,
      "step": 3600
    },
    {
      "epoch": 0.6371945860432413,
      "grad_norm": 4.8660688400268555,
      "learning_rate": 7.266654948145545e-05,
      "loss": 0.5837,
      "step": 3625
    },
    {
      "epoch": 0.6415890314642292,
      "grad_norm": 5.581780910491943,
      "learning_rate": 7.178766039725787e-05,
      "loss": 0.6078,
      "step": 3650
    },
    {
      "epoch": 0.6459834768852171,
      "grad_norm": 4.799681186676025,
      "learning_rate": 7.09087713130603e-05,
      "loss": 0.5875,
      "step": 3675
    },
    {
      "epoch": 0.650377922306205,
      "grad_norm": 5.736183166503906,
      "learning_rate": 7.002988222886272e-05,
      "loss": 0.5722,
      "step": 3700
    },
    {
      "epoch": 0.6547723677271928,
      "grad_norm": 4.765737056732178,
      "learning_rate": 6.915099314466514e-05,
      "loss": 0.5343,
      "step": 3725
    },
    {
      "epoch": 0.6591668131481807,
      "grad_norm": 4.924505233764648,
      "learning_rate": 6.827210406046757e-05,
      "loss": 0.5768,
      "step": 3750
    },
    {
      "epoch": 0.6635612585691686,
      "grad_norm": 4.176955699920654,
      "learning_rate": 6.739321497627e-05,
      "loss": 0.5664,
      "step": 3775
    },
    {
      "epoch": 0.6679557039901565,
      "grad_norm": 5.069204807281494,
      "learning_rate": 6.651432589207242e-05,
      "loss": 0.5462,
      "step": 3800
    },
    {
      "epoch": 0.6723501494111443,
      "grad_norm": 4.669108867645264,
      "learning_rate": 6.563543680787485e-05,
      "loss": 0.5705,
      "step": 3825
    },
    {
      "epoch": 0.6767445948321322,
      "grad_norm": 6.139380931854248,
      "learning_rate": 6.475654772367727e-05,
      "loss": 0.5407,
      "step": 3850
    },
    {
      "epoch": 0.6811390402531201,
      "grad_norm": 4.90459680557251,
      "learning_rate": 6.387765863947969e-05,
      "loss": 0.572,
      "step": 3875
    },
    {
      "epoch": 0.6855334856741079,
      "grad_norm": 3.8765673637390137,
      "learning_rate": 6.299876955528212e-05,
      "loss": 0.5519,
      "step": 3900
    },
    {
      "epoch": 0.6899279310950958,
      "grad_norm": 4.344926834106445,
      "learning_rate": 6.211988047108456e-05,
      "loss": 0.5447,
      "step": 3925
    },
    {
      "epoch": 0.6943223765160836,
      "grad_norm": 3.7995500564575195,
      "learning_rate": 6.124099138688697e-05,
      "loss": 0.5333,
      "step": 3950
    },
    {
      "epoch": 0.6987168219370715,
      "grad_norm": 3.4697988033294678,
      "learning_rate": 6.036210230268941e-05,
      "loss": 0.5034,
      "step": 3975
    },
    {
      "epoch": 0.7031112673580594,
      "grad_norm": 3.7044711112976074,
      "learning_rate": 5.9483213218491826e-05,
      "loss": 0.5573,
      "step": 4000
    },
    {
      "epoch": 0.7075057127790473,
      "grad_norm": 3.9104387760162354,
      "learning_rate": 5.860432413429425e-05,
      "loss": 0.5018,
      "step": 4025
    },
    {
      "epoch": 0.7119001582000352,
      "grad_norm": 4.043728351593018,
      "learning_rate": 5.7725435050096676e-05,
      "loss": 0.551,
      "step": 4050
    },
    {
      "epoch": 0.716294603621023,
      "grad_norm": 4.249601364135742,
      "learning_rate": 5.684654596589911e-05,
      "loss": 0.5163,
      "step": 4075
    },
    {
      "epoch": 0.7206890490420109,
      "grad_norm": 5.070849418640137,
      "learning_rate": 5.5967656881701534e-05,
      "loss": 0.5054,
      "step": 4100
    },
    {
      "epoch": 0.7250834944629988,
      "grad_norm": 4.732997894287109,
      "learning_rate": 5.508876779750396e-05,
      "loss": 0.5021,
      "step": 4125
    },
    {
      "epoch": 0.7294779398839867,
      "grad_norm": 3.3858466148376465,
      "learning_rate": 5.4209878713306385e-05,
      "loss": 0.5448,
      "step": 4150
    },
    {
      "epoch": 0.7338723853049746,
      "grad_norm": 4.307272434234619,
      "learning_rate": 5.333098962910881e-05,
      "loss": 0.5601,
      "step": 4175
    },
    {
      "epoch": 0.7382668307259623,
      "grad_norm": 4.258949279785156,
      "learning_rate": 5.245210054491123e-05,
      "loss": 0.5371,
      "step": 4200
    },
    {
      "epoch": 0.7426612761469502,
      "grad_norm": 4.0953521728515625,
      "learning_rate": 5.1573211460713654e-05,
      "loss": 0.5159,
      "step": 4225
    },
    {
      "epoch": 0.7470557215679381,
      "grad_norm": 4.595259666442871,
      "learning_rate": 5.069432237651609e-05,
      "loss": 0.4965,
      "step": 4250
    },
    {
      "epoch": 0.751450166988926,
      "grad_norm": 7.1846466064453125,
      "learning_rate": 4.981543329231851e-05,
      "loss": 0.5005,
      "step": 4275
    },
    {
      "epoch": 0.7558446124099139,
      "grad_norm": 5.5759711265563965,
      "learning_rate": 4.893654420812094e-05,
      "loss": 0.5303,
      "step": 4300
    },
    {
      "epoch": 0.7602390578309017,
      "grad_norm": 4.160124778747559,
      "learning_rate": 4.805765512392336e-05,
      "loss": 0.4803,
      "step": 4325
    },
    {
      "epoch": 0.7646335032518896,
      "grad_norm": 5.470555782318115,
      "learning_rate": 4.7178766039725794e-05,
      "loss": 0.4996,
      "step": 4350
    },
    {
      "epoch": 0.7690279486728775,
      "grad_norm": 4.330630302429199,
      "learning_rate": 4.629987695552821e-05,
      "loss": 0.5253,
      "step": 4375
    },
    {
      "epoch": 0.7734223940938654,
      "grad_norm": 4.55859899520874,
      "learning_rate": 4.542098787133064e-05,
      "loss": 0.4881,
      "step": 4400
    },
    {
      "epoch": 0.7778168395148533,
      "grad_norm": 3.9072351455688477,
      "learning_rate": 4.454209878713307e-05,
      "loss": 0.5048,
      "step": 4425
    },
    {
      "epoch": 0.7822112849358411,
      "grad_norm": 5.034299373626709,
      "learning_rate": 4.3663209702935496e-05,
      "loss": 0.478,
      "step": 4450
    },
    {
      "epoch": 0.786605730356829,
      "grad_norm": 4.582981586456299,
      "learning_rate": 4.2784320618737914e-05,
      "loss": 0.5313,
      "step": 4475
    },
    {
      "epoch": 0.7910001757778169,
      "grad_norm": 4.53229284286499,
      "learning_rate": 4.190543153454034e-05,
      "loss": 0.4946,
      "step": 4500
    },
    {
      "epoch": 0.7953946211988047,
      "grad_norm": 4.112471580505371,
      "learning_rate": 4.102654245034277e-05,
      "loss": 0.4854,
      "step": 4525
    },
    {
      "epoch": 0.7997890666197925,
      "grad_norm": 4.303210258483887,
      "learning_rate": 4.014765336614519e-05,
      "loss": 0.5011,
      "step": 4550
    },
    {
      "epoch": 0.8041835120407804,
      "grad_norm": 4.6794514656066895,
      "learning_rate": 3.9268764281947616e-05,
      "loss": 0.5102,
      "step": 4575
    },
    {
      "epoch": 0.8085779574617683,
      "grad_norm": 3.789486885070801,
      "learning_rate": 3.838987519775005e-05,
      "loss": 0.4977,
      "step": 4600
    },
    {
      "epoch": 0.8129724028827562,
      "grad_norm": 5.029468536376953,
      "learning_rate": 3.7510986113552473e-05,
      "loss": 0.4728,
      "step": 4625
    },
    {
      "epoch": 0.8173668483037441,
      "grad_norm": 3.3264567852020264,
      "learning_rate": 3.663209702935489e-05,
      "loss": 0.4814,
      "step": 4650
    },
    {
      "epoch": 0.821761293724732,
      "grad_norm": 3.7521538734436035,
      "learning_rate": 3.5753207945157324e-05,
      "loss": 0.4802,
      "step": 4675
    },
    {
      "epoch": 0.8261557391457198,
      "grad_norm": 4.107119560241699,
      "learning_rate": 3.487431886095975e-05,
      "loss": 0.4522,
      "step": 4700
    },
    {
      "epoch": 0.8305501845667077,
      "grad_norm": 5.576258182525635,
      "learning_rate": 3.3995429776762175e-05,
      "loss": 0.4804,
      "step": 4725
    },
    {
      "epoch": 0.8349446299876956,
      "grad_norm": 5.554751873016357,
      "learning_rate": 3.31165406925646e-05,
      "loss": 0.5064,
      "step": 4750
    },
    {
      "epoch": 0.8393390754086835,
      "grad_norm": 4.669742107391357,
      "learning_rate": 3.2237651608367026e-05,
      "loss": 0.5101,
      "step": 4775
    },
    {
      "epoch": 0.8437335208296713,
      "grad_norm": 4.228029727935791,
      "learning_rate": 3.135876252416945e-05,
      "loss": 0.4285,
      "step": 4800
    },
    {
      "epoch": 0.8481279662506591,
      "grad_norm": 4.760587215423584,
      "learning_rate": 3.047987343997188e-05,
      "loss": 0.46,
      "step": 4825
    },
    {
      "epoch": 0.852522411671647,
      "grad_norm": 4.521291255950928,
      "learning_rate": 2.9600984355774302e-05,
      "loss": 0.4705,
      "step": 4850
    },
    {
      "epoch": 0.8569168570926349,
      "grad_norm": 3.4773335456848145,
      "learning_rate": 2.8722095271576727e-05,
      "loss": 0.4832,
      "step": 4875
    },
    {
      "epoch": 0.8613113025136228,
      "grad_norm": 5.295111179351807,
      "learning_rate": 2.7843206187379156e-05,
      "loss": 0.4689,
      "step": 4900
    },
    {
      "epoch": 0.8657057479346106,
      "grad_norm": 4.02949857711792,
      "learning_rate": 2.696431710318158e-05,
      "loss": 0.4523,
      "step": 4925
    },
    {
      "epoch": 0.8701001933555985,
      "grad_norm": 4.176213264465332,
      "learning_rate": 2.6085428018984003e-05,
      "loss": 0.4696,
      "step": 4950
    },
    {
      "epoch": 0.8744946387765864,
      "grad_norm": 4.254176616668701,
      "learning_rate": 2.5206538934786432e-05,
      "loss": 0.4521,
      "step": 4975
    },
    {
      "epoch": 0.8788890841975743,
      "grad_norm": 4.777898788452148,
      "learning_rate": 2.4327649850588857e-05,
      "loss": 0.4797,
      "step": 5000
    },
    {
      "epoch": 0.8832835296185622,
      "grad_norm": 3.3330860137939453,
      "learning_rate": 2.3448760766391283e-05,
      "loss": 0.483,
      "step": 5025
    },
    {
      "epoch": 0.88767797503955,
      "grad_norm": 4.118786811828613,
      "learning_rate": 2.2569871682193708e-05,
      "loss": 0.4436,
      "step": 5050
    },
    {
      "epoch": 0.8920724204605379,
      "grad_norm": 4.675077438354492,
      "learning_rate": 2.1690982597996133e-05,
      "loss": 0.4774,
      "step": 5075
    },
    {
      "epoch": 0.8964668658815258,
      "grad_norm": 3.4711081981658936,
      "learning_rate": 2.081209351379856e-05,
      "loss": 0.4419,
      "step": 5100
    },
    {
      "epoch": 0.9008613113025136,
      "grad_norm": 5.026766300201416,
      "learning_rate": 1.9933204429600984e-05,
      "loss": 0.4715,
      "step": 5125
    },
    {
      "epoch": 0.9052557567235014,
      "grad_norm": 3.032031774520874,
      "learning_rate": 1.9054315345403413e-05,
      "loss": 0.4396,
      "step": 5150
    },
    {
      "epoch": 0.9096502021444893,
      "grad_norm": 4.477692604064941,
      "learning_rate": 1.8175426261205835e-05,
      "loss": 0.4652,
      "step": 5175
    },
    {
      "epoch": 0.9140446475654772,
      "grad_norm": 5.3540940284729,
      "learning_rate": 1.7296537177008264e-05,
      "loss": 0.4638,
      "step": 5200
    },
    {
      "epoch": 0.9184390929864651,
      "grad_norm": 4.0367937088012695,
      "learning_rate": 1.641764809281069e-05,
      "loss": 0.4076,
      "step": 5225
    },
    {
      "epoch": 0.922833538407453,
      "grad_norm": 4.341006755828857,
      "learning_rate": 1.5538759008613114e-05,
      "loss": 0.4558,
      "step": 5250
    },
    {
      "epoch": 0.9272279838284408,
      "grad_norm": 3.60497784614563,
      "learning_rate": 1.465986992441554e-05,
      "loss": 0.4261,
      "step": 5275
    },
    {
      "epoch": 0.9316224292494287,
      "grad_norm": 4.133943557739258,
      "learning_rate": 1.3780980840217967e-05,
      "loss": 0.428,
      "step": 5300
    },
    {
      "epoch": 0.9360168746704166,
      "grad_norm": 6.612752914428711,
      "learning_rate": 1.290209175602039e-05,
      "loss": 0.4206,
      "step": 5325
    },
    {
      "epoch": 0.9404113200914045,
      "grad_norm": 5.042158603668213,
      "learning_rate": 1.2023202671822818e-05,
      "loss": 0.4727,
      "step": 5350
    },
    {
      "epoch": 0.9448057655123924,
      "grad_norm": 5.22438907623291,
      "learning_rate": 1.1144313587625243e-05,
      "loss": 0.4445,
      "step": 5375
    },
    {
      "epoch": 0.9492002109333803,
      "grad_norm": 4.81308650970459,
      "learning_rate": 1.0265424503427668e-05,
      "loss": 0.4769,
      "step": 5400
    },
    {
      "epoch": 0.9535946563543681,
      "grad_norm": 4.105576038360596,
      "learning_rate": 9.386535419230094e-06,
      "loss": 0.4645,
      "step": 5425
    },
    {
      "epoch": 0.9579891017753559,
      "grad_norm": 4.702960968017578,
      "learning_rate": 8.507646335032519e-06,
      "loss": 0.4206,
      "step": 5450
    },
    {
      "epoch": 0.9623835471963438,
      "grad_norm": 3.4760286808013916,
      "learning_rate": 7.628757250834944e-06,
      "loss": 0.4413,
      "step": 5475
    },
    {
      "epoch": 0.9667779926173317,
      "grad_norm": 4.738360404968262,
      "learning_rate": 6.74986816663737e-06,
      "loss": 0.4873,
      "step": 5500
    },
    {
      "epoch": 0.9711724380383195,
      "grad_norm": 4.266371726989746,
      "learning_rate": 5.870979082439797e-06,
      "loss": 0.4543,
      "step": 5525
    },
    {
      "epoch": 0.9755668834593074,
      "grad_norm": 3.5802500247955322,
      "learning_rate": 4.992089998242222e-06,
      "loss": 0.4266,
      "step": 5550
    },
    {
      "epoch": 0.9799613288802953,
      "grad_norm": 3.6179189682006836,
      "learning_rate": 4.113200914044648e-06,
      "loss": 0.4383,
      "step": 5575
    },
    {
      "epoch": 0.9843557743012832,
      "grad_norm": 3.617515802383423,
      "learning_rate": 3.2343118298470733e-06,
      "loss": 0.4805,
      "step": 5600
    },
    {
      "epoch": 0.9887502197222711,
      "grad_norm": 3.8106040954589844,
      "learning_rate": 2.355422745649499e-06,
      "loss": 0.475,
      "step": 5625
    },
    {
      "epoch": 0.9931446651432589,
      "grad_norm": 5.114136695861816,
      "learning_rate": 1.4765336614519249e-06,
      "loss": 0.4471,
      "step": 5650
    },
    {
      "epoch": 0.9975391105642468,
      "grad_norm": 4.28861665725708,
      "learning_rate": 5.976445772543506e-07,
      "loss": 0.4512,
      "step": 5675
    }
  ],
  "logging_steps": 25,
  "max_steps": 5689,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.950561664573112e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
