{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5689,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004394445420987872,
      "grad_norm": 4.088820934295654,
      "learning_rate": 0.00019915626647917033,
      "loss": 0.1888,
      "step": 25
    },
    {
      "epoch": 0.008788890841975743,
      "grad_norm": 3.9643521308898926,
      "learning_rate": 0.00019827737739497276,
      "loss": 0.2118,
      "step": 50
    },
    {
      "epoch": 0.013183336262963615,
      "grad_norm": 4.788534164428711,
      "learning_rate": 0.0001973984883107752,
      "loss": 0.2316,
      "step": 75
    },
    {
      "epoch": 0.017577781683951486,
      "grad_norm": 5.613518714904785,
      "learning_rate": 0.0001965547547899455,
      "loss": 0.2362,
      "step": 100
    },
    {
      "epoch": 0.021972227104939356,
      "grad_norm": 4.763377666473389,
      "learning_rate": 0.00019567586570574795,
      "loss": 0.2365,
      "step": 125
    },
    {
      "epoch": 0.02636667252592723,
      "grad_norm": 3.6330883502960205,
      "learning_rate": 0.00019479697662155038,
      "loss": 0.2322,
      "step": 150
    },
    {
      "epoch": 0.0307611179469151,
      "grad_norm": 3.745412826538086,
      "learning_rate": 0.00019391808753735278,
      "loss": 0.2349,
      "step": 175
    },
    {
      "epoch": 0.03515556336790297,
      "grad_norm": 5.1942243576049805,
      "learning_rate": 0.00019303919845315521,
      "loss": 0.2481,
      "step": 200
    },
    {
      "epoch": 0.03955000878889084,
      "grad_norm": 6.052046298980713,
      "learning_rate": 0.00019216030936895765,
      "loss": 0.2629,
      "step": 225
    },
    {
      "epoch": 0.04394445420987871,
      "grad_norm": 6.143415927886963,
      "learning_rate": 0.00019128142028476008,
      "loss": 0.2561,
      "step": 250
    },
    {
      "epoch": 0.048338899630866586,
      "grad_norm": 5.635751247406006,
      "learning_rate": 0.0001904025312005625,
      "loss": 0.2734,
      "step": 275
    },
    {
      "epoch": 0.05273334505185446,
      "grad_norm": 6.183475494384766,
      "learning_rate": 0.00018952364211636494,
      "loss": 0.2516,
      "step": 300
    },
    {
      "epoch": 0.057127790472842326,
      "grad_norm": 4.231283664703369,
      "learning_rate": 0.00018864475303216735,
      "loss": 0.2753,
      "step": 325
    },
    {
      "epoch": 0.0615222358938302,
      "grad_norm": 4.274719715118408,
      "learning_rate": 0.00018776586394796978,
      "loss": 0.2625,
      "step": 350
    },
    {
      "epoch": 0.06591668131481807,
      "grad_norm": 4.606522083282471,
      "learning_rate": 0.0001868869748637722,
      "loss": 0.2674,
      "step": 375
    },
    {
      "epoch": 0.07031112673580595,
      "grad_norm": 4.622740745544434,
      "learning_rate": 0.00018600808577957462,
      "loss": 0.2682,
      "step": 400
    },
    {
      "epoch": 0.07470557215679381,
      "grad_norm": 5.0051045417785645,
      "learning_rate": 0.00018512919669537705,
      "loss": 0.2689,
      "step": 425
    },
    {
      "epoch": 0.07910001757778168,
      "grad_norm": 5.09605073928833,
      "learning_rate": 0.00018425030761117948,
      "loss": 0.2724,
      "step": 450
    },
    {
      "epoch": 0.08349446299876956,
      "grad_norm": 5.443545341491699,
      "learning_rate": 0.0001833714185269819,
      "loss": 0.2625,
      "step": 475
    },
    {
      "epoch": 0.08788890841975742,
      "grad_norm": 5.974084377288818,
      "learning_rate": 0.00018249252944278432,
      "loss": 0.2769,
      "step": 500
    },
    {
      "epoch": 0.09228335384074529,
      "grad_norm": 4.911219120025635,
      "learning_rate": 0.00018161364035858675,
      "loss": 0.2865,
      "step": 525
    },
    {
      "epoch": 0.09667779926173317,
      "grad_norm": 3.9968461990356445,
      "learning_rate": 0.00018073475127438918,
      "loss": 0.2768,
      "step": 550
    },
    {
      "epoch": 0.10107224468272104,
      "grad_norm": 5.679508686065674,
      "learning_rate": 0.00017985586219019162,
      "loss": 0.2741,
      "step": 575
    },
    {
      "epoch": 0.10546669010370892,
      "grad_norm": 5.461188316345215,
      "learning_rate": 0.00017897697310599405,
      "loss": 0.275,
      "step": 600
    },
    {
      "epoch": 0.10986113552469678,
      "grad_norm": 3.9393794536590576,
      "learning_rate": 0.00017809808402179645,
      "loss": 0.2619,
      "step": 625
    },
    {
      "epoch": 0.11425558094568465,
      "grad_norm": 5.265918254852295,
      "learning_rate": 0.00017721919493759888,
      "loss": 0.2658,
      "step": 650
    },
    {
      "epoch": 0.11865002636667253,
      "grad_norm": 4.407367706298828,
      "learning_rate": 0.00017634030585340132,
      "loss": 0.2672,
      "step": 675
    },
    {
      "epoch": 0.1230444717876604,
      "grad_norm": 4.381012916564941,
      "learning_rate": 0.00017546141676920372,
      "loss": 0.2726,
      "step": 700
    },
    {
      "epoch": 0.12743891720864828,
      "grad_norm": 5.061550617218018,
      "learning_rate": 0.00017458252768500615,
      "loss": 0.2836,
      "step": 725
    },
    {
      "epoch": 0.13183336262963613,
      "grad_norm": 4.746260166168213,
      "learning_rate": 0.00017370363860080859,
      "loss": 0.2647,
      "step": 750
    },
    {
      "epoch": 0.136227808050624,
      "grad_norm": 6.089895725250244,
      "learning_rate": 0.0001728599050799789,
      "loss": 0.2712,
      "step": 775
    },
    {
      "epoch": 0.1406222534716119,
      "grad_norm": 3.7141764163970947,
      "learning_rate": 0.00017198101599578134,
      "loss": 0.2522,
      "step": 800
    },
    {
      "epoch": 0.14501669889259974,
      "grad_norm": 6.055250644683838,
      "learning_rate": 0.00017110212691158377,
      "loss": 0.2717,
      "step": 825
    },
    {
      "epoch": 0.14941114431358762,
      "grad_norm": 4.153378486633301,
      "learning_rate": 0.000170293548954122,
      "loss": 0.2705,
      "step": 850
    },
    {
      "epoch": 0.1538055897345755,
      "grad_norm": 4.941743850708008,
      "learning_rate": 0.0001694146598699244,
      "loss": 0.2724,
      "step": 875
    },
    {
      "epoch": 0.15820003515556336,
      "grad_norm": 3.493302345275879,
      "learning_rate": 0.00016853577078572684,
      "loss": 0.2671,
      "step": 900
    },
    {
      "epoch": 0.16259448057655124,
      "grad_norm": 4.0702691078186035,
      "learning_rate": 0.00016765688170152927,
      "loss": 0.2812,
      "step": 925
    },
    {
      "epoch": 0.16698892599753912,
      "grad_norm": 4.082756519317627,
      "learning_rate": 0.00016677799261733168,
      "loss": 0.2635,
      "step": 950
    },
    {
      "epoch": 0.17138337141852697,
      "grad_norm": 4.2766242027282715,
      "learning_rate": 0.00016589910353313414,
      "loss": 0.2582,
      "step": 975
    },
    {
      "epoch": 0.17577781683951485,
      "grad_norm": 5.182312965393066,
      "learning_rate": 0.00016502021444893657,
      "loss": 0.2651,
      "step": 1000
    },
    {
      "epoch": 0.18017226226050273,
      "grad_norm": 4.170616149902344,
      "learning_rate": 0.00016414132536473898,
      "loss": 0.2668,
      "step": 1025
    },
    {
      "epoch": 0.18456670768149058,
      "grad_norm": 4.815769195556641,
      "learning_rate": 0.0001632624362805414,
      "loss": 0.2842,
      "step": 1050
    },
    {
      "epoch": 0.18896115310247846,
      "grad_norm": 4.053970813751221,
      "learning_rate": 0.00016238354719634384,
      "loss": 0.2733,
      "step": 1075
    },
    {
      "epoch": 0.19335559852346634,
      "grad_norm": 4.733868598937988,
      "learning_rate": 0.00016150465811214624,
      "loss": 0.2765,
      "step": 1100
    },
    {
      "epoch": 0.19775004394445422,
      "grad_norm": 4.979613780975342,
      "learning_rate": 0.00016062576902794868,
      "loss": 0.2875,
      "step": 1125
    },
    {
      "epoch": 0.20214448936544208,
      "grad_norm": 4.816731929779053,
      "learning_rate": 0.0001597468799437511,
      "loss": 0.259,
      "step": 1150
    },
    {
      "epoch": 0.20653893478642996,
      "grad_norm": 4.507692337036133,
      "learning_rate": 0.00015886799085955354,
      "loss": 0.249,
      "step": 1175
    },
    {
      "epoch": 0.21093338020741784,
      "grad_norm": 4.771302700042725,
      "learning_rate": 0.00015798910177535595,
      "loss": 0.256,
      "step": 1200
    },
    {
      "epoch": 0.2153278256284057,
      "grad_norm": 4.621272087097168,
      "learning_rate": 0.00015711021269115838,
      "loss": 0.2849,
      "step": 1225
    },
    {
      "epoch": 0.21972227104939357,
      "grad_norm": 3.8168773651123047,
      "learning_rate": 0.0001562313236069608,
      "loss": 0.2707,
      "step": 1250
    },
    {
      "epoch": 0.22411671647038145,
      "grad_norm": 4.881567001342773,
      "learning_rate": 0.00015535243452276322,
      "loss": 0.2579,
      "step": 1275
    },
    {
      "epoch": 0.2285111618913693,
      "grad_norm": 4.959708213806152,
      "learning_rate": 0.00015447354543856567,
      "loss": 0.2528,
      "step": 1300
    },
    {
      "epoch": 0.23290560731235718,
      "grad_norm": 5.223938465118408,
      "learning_rate": 0.0001535946563543681,
      "loss": 0.2554,
      "step": 1325
    },
    {
      "epoch": 0.23730005273334506,
      "grad_norm": 3.5111501216888428,
      "learning_rate": 0.0001527157672701705,
      "loss": 0.2532,
      "step": 1350
    },
    {
      "epoch": 0.24169449815433292,
      "grad_norm": 3.6376352310180664,
      "learning_rate": 0.00015183687818597294,
      "loss": 0.2538,
      "step": 1375
    },
    {
      "epoch": 0.2460889435753208,
      "grad_norm": 4.766878128051758,
      "learning_rate": 0.00015095798910177538,
      "loss": 0.2732,
      "step": 1400
    },
    {
      "epoch": 0.2504833889963087,
      "grad_norm": 7.303184986114502,
      "learning_rate": 0.00015007910001757778,
      "loss": 0.252,
      "step": 1425
    },
    {
      "epoch": 0.25487783441729656,
      "grad_norm": 3.891350746154785,
      "learning_rate": 0.0001492002109333802,
      "loss": 0.2559,
      "step": 1450
    },
    {
      "epoch": 0.25927227983828444,
      "grad_norm": 5.160451412200928,
      "learning_rate": 0.00014832132184918265,
      "loss": 0.28,
      "step": 1475
    },
    {
      "epoch": 0.26366672525927226,
      "grad_norm": 3.9723103046417236,
      "learning_rate": 0.00014744243276498505,
      "loss": 0.2459,
      "step": 1500
    },
    {
      "epoch": 0.26806117068026014,
      "grad_norm": 5.5167155265808105,
      "learning_rate": 0.00014656354368078748,
      "loss": 0.2624,
      "step": 1525
    },
    {
      "epoch": 0.272455616101248,
      "grad_norm": 4.257079124450684,
      "learning_rate": 0.00014568465459658991,
      "loss": 0.2565,
      "step": 1550
    },
    {
      "epoch": 0.2768500615222359,
      "grad_norm": 3.921177387237549,
      "learning_rate": 0.00014480576551239232,
      "loss": 0.2548,
      "step": 1575
    },
    {
      "epoch": 0.2812445069432238,
      "grad_norm": 4.533613681793213,
      "learning_rate": 0.00014392687642819478,
      "loss": 0.2484,
      "step": 1600
    },
    {
      "epoch": 0.28563895236421166,
      "grad_norm": 3.748178005218506,
      "learning_rate": 0.0001430479873439972,
      "loss": 0.2621,
      "step": 1625
    },
    {
      "epoch": 0.2900333977851995,
      "grad_norm": 4.552666187286377,
      "learning_rate": 0.00014216909825979962,
      "loss": 0.2513,
      "step": 1650
    },
    {
      "epoch": 0.29442784320618737,
      "grad_norm": 5.060998439788818,
      "learning_rate": 0.00014129020917560205,
      "loss": 0.2671,
      "step": 1675
    },
    {
      "epoch": 0.29882228862717525,
      "grad_norm": 4.02919340133667,
      "learning_rate": 0.00014041132009140448,
      "loss": 0.2527,
      "step": 1700
    },
    {
      "epoch": 0.30321673404816313,
      "grad_norm": 3.840150833129883,
      "learning_rate": 0.00013953243100720689,
      "loss": 0.2406,
      "step": 1725
    },
    {
      "epoch": 0.307611179469151,
      "grad_norm": 5.229345798492432,
      "learning_rate": 0.00013865354192300932,
      "loss": 0.2362,
      "step": 1750
    },
    {
      "epoch": 0.3120056248901389,
      "grad_norm": 5.834038257598877,
      "learning_rate": 0.00013777465283881175,
      "loss": 0.2572,
      "step": 1775
    },
    {
      "epoch": 0.3164000703111267,
      "grad_norm": 2.7669012546539307,
      "learning_rate": 0.00013689576375461418,
      "loss": 0.2509,
      "step": 1800
    },
    {
      "epoch": 0.3207945157321146,
      "grad_norm": 3.8895931243896484,
      "learning_rate": 0.0001360168746704166,
      "loss": 0.2457,
      "step": 1825
    },
    {
      "epoch": 0.3251889611531025,
      "grad_norm": 3.4242498874664307,
      "learning_rate": 0.00013513798558621902,
      "loss": 0.2399,
      "step": 1850
    },
    {
      "epoch": 0.32958340657409035,
      "grad_norm": 5.957260608673096,
      "learning_rate": 0.00013425909650202145,
      "loss": 0.2375,
      "step": 1875
    },
    {
      "epoch": 0.33397785199507823,
      "grad_norm": 5.137997627258301,
      "learning_rate": 0.00013338020741782388,
      "loss": 0.2634,
      "step": 1900
    },
    {
      "epoch": 0.3383722974160661,
      "grad_norm": 3.7053706645965576,
      "learning_rate": 0.00013250131833362632,
      "loss": 0.2328,
      "step": 1925
    },
    {
      "epoch": 0.34276674283705394,
      "grad_norm": 5.387033462524414,
      "learning_rate": 0.00013162242924942875,
      "loss": 0.2426,
      "step": 1950
    },
    {
      "epoch": 0.3471611882580418,
      "grad_norm": 3.69149112701416,
      "learning_rate": 0.00013074354016523115,
      "loss": 0.254,
      "step": 1975
    },
    {
      "epoch": 0.3515556336790297,
      "grad_norm": 4.276498317718506,
      "learning_rate": 0.00012986465108103359,
      "loss": 0.2408,
      "step": 2000
    },
    {
      "epoch": 0.3559500791000176,
      "grad_norm": 4.999208927154541,
      "learning_rate": 0.00012898576199683602,
      "loss": 0.2446,
      "step": 2025
    },
    {
      "epoch": 0.36034452452100546,
      "grad_norm": 2.592367172241211,
      "learning_rate": 0.00012810687291263842,
      "loss": 0.2378,
      "step": 2050
    },
    {
      "epoch": 0.36473896994199334,
      "grad_norm": 3.9582877159118652,
      "learning_rate": 0.00012722798382844085,
      "loss": 0.2252,
      "step": 2075
    },
    {
      "epoch": 0.36913341536298117,
      "grad_norm": 3.4433786869049072,
      "learning_rate": 0.0001263490947442433,
      "loss": 0.226,
      "step": 2100
    },
    {
      "epoch": 0.37352786078396905,
      "grad_norm": 4.428585529327393,
      "learning_rate": 0.0001254702056600457,
      "loss": 0.2207,
      "step": 2125
    },
    {
      "epoch": 0.3779223062049569,
      "grad_norm": 3.6593496799468994,
      "learning_rate": 0.00012459131657584812,
      "loss": 0.236,
      "step": 2150
    },
    {
      "epoch": 0.3823167516259448,
      "grad_norm": 4.204270839691162,
      "learning_rate": 0.00012371242749165056,
      "loss": 0.2334,
      "step": 2175
    },
    {
      "epoch": 0.3867111970469327,
      "grad_norm": 4.750671863555908,
      "learning_rate": 0.000122833538407453,
      "loss": 0.2362,
      "step": 2200
    },
    {
      "epoch": 0.39110564246792057,
      "grad_norm": 4.21592378616333,
      "learning_rate": 0.00012195464932325542,
      "loss": 0.2188,
      "step": 2225
    },
    {
      "epoch": 0.39550008788890845,
      "grad_norm": 4.0355544090271,
      "learning_rate": 0.00012107576023905784,
      "loss": 0.22,
      "step": 2250
    },
    {
      "epoch": 0.39989453330989627,
      "grad_norm": 4.323007106781006,
      "learning_rate": 0.00012019687115486027,
      "loss": 0.2297,
      "step": 2275
    },
    {
      "epoch": 0.40428897873088415,
      "grad_norm": 4.379055976867676,
      "learning_rate": 0.00011931798207066269,
      "loss": 0.2433,
      "step": 2300
    },
    {
      "epoch": 0.40868342415187203,
      "grad_norm": 5.0143818855285645,
      "learning_rate": 0.00011843909298646512,
      "loss": 0.2267,
      "step": 2325
    },
    {
      "epoch": 0.4130778695728599,
      "grad_norm": 5.020726680755615,
      "learning_rate": 0.00011756020390226754,
      "loss": 0.2459,
      "step": 2350
    },
    {
      "epoch": 0.4174723149938478,
      "grad_norm": 4.292403697967529,
      "learning_rate": 0.00011668131481806996,
      "loss": 0.2394,
      "step": 2375
    },
    {
      "epoch": 0.4218667604148357,
      "grad_norm": 3.5802056789398193,
      "learning_rate": 0.00011580242573387239,
      "loss": 0.2345,
      "step": 2400
    },
    {
      "epoch": 0.4262612058358235,
      "grad_norm": 4.6321282386779785,
      "learning_rate": 0.00011492353664967481,
      "loss": 0.2263,
      "step": 2425
    },
    {
      "epoch": 0.4306556512568114,
      "grad_norm": 4.4037861824035645,
      "learning_rate": 0.00011404464756547724,
      "loss": 0.2369,
      "step": 2450
    },
    {
      "epoch": 0.43505009667779926,
      "grad_norm": 4.3022074699401855,
      "learning_rate": 0.00011316575848127966,
      "loss": 0.2265,
      "step": 2475
    },
    {
      "epoch": 0.43944454209878714,
      "grad_norm": 3.821648597717285,
      "learning_rate": 0.00011228686939708208,
      "loss": 0.2302,
      "step": 2500
    },
    {
      "epoch": 0.443838987519775,
      "grad_norm": 3.635554790496826,
      "learning_rate": 0.00011140798031288452,
      "loss": 0.228,
      "step": 2525
    },
    {
      "epoch": 0.4482334329407629,
      "grad_norm": 5.295759201049805,
      "learning_rate": 0.00011052909122868696,
      "loss": 0.2384,
      "step": 2550
    },
    {
      "epoch": 0.4526278783617507,
      "grad_norm": 3.712050676345825,
      "learning_rate": 0.00010965020214448938,
      "loss": 0.2194,
      "step": 2575
    },
    {
      "epoch": 0.4570223237827386,
      "grad_norm": 3.1584510803222656,
      "learning_rate": 0.00010877131306029181,
      "loss": 0.2235,
      "step": 2600
    },
    {
      "epoch": 0.4614167692037265,
      "grad_norm": 4.5504255294799805,
      "learning_rate": 0.00010789242397609423,
      "loss": 0.2204,
      "step": 2625
    },
    {
      "epoch": 0.46581121462471436,
      "grad_norm": 4.8551154136657715,
      "learning_rate": 0.00010701353489189664,
      "loss": 0.2383,
      "step": 2650
    },
    {
      "epoch": 0.47020566004570225,
      "grad_norm": 3.8772077560424805,
      "learning_rate": 0.00010613464580769908,
      "loss": 0.2333,
      "step": 2675
    },
    {
      "epoch": 0.4746001054666901,
      "grad_norm": 3.9055190086364746,
      "learning_rate": 0.0001052557567235015,
      "loss": 0.2267,
      "step": 2700
    },
    {
      "epoch": 0.47899455088767795,
      "grad_norm": 3.558906316757202,
      "learning_rate": 0.00010437686763930393,
      "loss": 0.217,
      "step": 2725
    },
    {
      "epoch": 0.48338899630866583,
      "grad_norm": 4.188171863555908,
      "learning_rate": 0.00010349797855510635,
      "loss": 0.2246,
      "step": 2750
    },
    {
      "epoch": 0.4877834417296537,
      "grad_norm": 2.716290235519409,
      "learning_rate": 0.00010261908947090876,
      "loss": 0.2129,
      "step": 2775
    },
    {
      "epoch": 0.4921778871506416,
      "grad_norm": 3.719515800476074,
      "learning_rate": 0.0001017402003867112,
      "loss": 0.2193,
      "step": 2800
    },
    {
      "epoch": 0.49657233257162947,
      "grad_norm": 3.6170172691345215,
      "learning_rate": 0.00010086131130251362,
      "loss": 0.2304,
      "step": 2825
    },
    {
      "epoch": 0.5009667779926174,
      "grad_norm": 4.088104248046875,
      "learning_rate": 9.998242221831605e-05,
      "loss": 0.2107,
      "step": 2850
    },
    {
      "epoch": 0.5053612234136052,
      "grad_norm": 3.1813056468963623,
      "learning_rate": 9.910353313411848e-05,
      "loss": 0.2209,
      "step": 2875
    },
    {
      "epoch": 0.5097556688345931,
      "grad_norm": 3.014061450958252,
      "learning_rate": 9.82246440499209e-05,
      "loss": 0.2189,
      "step": 2900
    },
    {
      "epoch": 0.514150114255581,
      "grad_norm": 4.465114116668701,
      "learning_rate": 9.734575496572333e-05,
      "loss": 0.222,
      "step": 2925
    },
    {
      "epoch": 0.5185445596765689,
      "grad_norm": 3.5416202545166016,
      "learning_rate": 9.646686588152576e-05,
      "loss": 0.2085,
      "step": 2950
    },
    {
      "epoch": 0.5229390050975566,
      "grad_norm": 4.152597904205322,
      "learning_rate": 9.558797679732818e-05,
      "loss": 0.2142,
      "step": 2975
    },
    {
      "epoch": 0.5273334505185445,
      "grad_norm": 5.191656589508057,
      "learning_rate": 9.470908771313061e-05,
      "loss": 0.2197,
      "step": 3000
    },
    {
      "epoch": 0.5317278959395324,
      "grad_norm": 3.2442972660064697,
      "learning_rate": 9.383019862893303e-05,
      "loss": 0.192,
      "step": 3025
    },
    {
      "epoch": 0.5361223413605203,
      "grad_norm": 3.646775722503662,
      "learning_rate": 9.295130954473545e-05,
      "loss": 0.2144,
      "step": 3050
    },
    {
      "epoch": 0.5405167867815082,
      "grad_norm": 3.0776479244232178,
      "learning_rate": 9.207242046053788e-05,
      "loss": 0.1963,
      "step": 3075
    },
    {
      "epoch": 0.544911232202496,
      "grad_norm": 2.8159077167510986,
      "learning_rate": 9.119353137634031e-05,
      "loss": 0.2111,
      "step": 3100
    },
    {
      "epoch": 0.5493056776234839,
      "grad_norm": 2.606062889099121,
      "learning_rate": 9.031464229214273e-05,
      "loss": 0.2033,
      "step": 3125
    },
    {
      "epoch": 0.5537001230444718,
      "grad_norm": 4.458380222320557,
      "learning_rate": 8.943575320794517e-05,
      "loss": 0.241,
      "step": 3150
    },
    {
      "epoch": 0.5580945684654597,
      "grad_norm": 3.6851084232330322,
      "learning_rate": 8.855686412374758e-05,
      "loss": 0.2123,
      "step": 3175
    },
    {
      "epoch": 0.5624890138864476,
      "grad_norm": 2.912771463394165,
      "learning_rate": 8.767797503955e-05,
      "loss": 0.2025,
      "step": 3200
    },
    {
      "epoch": 0.5668834593074354,
      "grad_norm": 3.1582043170928955,
      "learning_rate": 8.679908595535245e-05,
      "loss": 0.219,
      "step": 3225
    },
    {
      "epoch": 0.5712779047284233,
      "grad_norm": 3.647768259048462,
      "learning_rate": 8.592019687115487e-05,
      "loss": 0.2384,
      "step": 3250
    },
    {
      "epoch": 0.5756723501494111,
      "grad_norm": 3.9004170894622803,
      "learning_rate": 8.504130778695729e-05,
      "loss": 0.209,
      "step": 3275
    },
    {
      "epoch": 0.580066795570399,
      "grad_norm": 3.987816572189331,
      "learning_rate": 8.416241870275972e-05,
      "loss": 0.2112,
      "step": 3300
    },
    {
      "epoch": 0.5844612409913869,
      "grad_norm": 3.0082039833068848,
      "learning_rate": 8.328352961856214e-05,
      "loss": 0.213,
      "step": 3325
    },
    {
      "epoch": 0.5888556864123747,
      "grad_norm": 3.679650068283081,
      "learning_rate": 8.240464053436457e-05,
      "loss": 0.2205,
      "step": 3350
    },
    {
      "epoch": 0.5932501318333626,
      "grad_norm": 4.129452705383301,
      "learning_rate": 8.1525751450167e-05,
      "loss": 0.2074,
      "step": 3375
    },
    {
      "epoch": 0.5976445772543505,
      "grad_norm": 5.0081682205200195,
      "learning_rate": 8.064686236596942e-05,
      "loss": 0.2117,
      "step": 3400
    },
    {
      "epoch": 0.6020390226753384,
      "grad_norm": 4.062054634094238,
      "learning_rate": 7.976797328177185e-05,
      "loss": 0.2127,
      "step": 3425
    },
    {
      "epoch": 0.6064334680963263,
      "grad_norm": 3.200578212738037,
      "learning_rate": 7.888908419757427e-05,
      "loss": 0.2089,
      "step": 3450
    },
    {
      "epoch": 0.6108279135173141,
      "grad_norm": 4.261450290679932,
      "learning_rate": 7.801019511337669e-05,
      "loss": 0.1959,
      "step": 3475
    },
    {
      "epoch": 0.615222358938302,
      "grad_norm": 5.334554195404053,
      "learning_rate": 7.713130602917912e-05,
      "loss": 0.2321,
      "step": 3500
    },
    {
      "epoch": 0.6196168043592899,
      "grad_norm": 3.011669635772705,
      "learning_rate": 7.625241694498154e-05,
      "loss": 0.2059,
      "step": 3525
    },
    {
      "epoch": 0.6240112497802778,
      "grad_norm": 3.614776134490967,
      "learning_rate": 7.537352786078397e-05,
      "loss": 0.2084,
      "step": 3550
    },
    {
      "epoch": 0.6284056952012655,
      "grad_norm": 3.9997591972351074,
      "learning_rate": 7.44946387765864e-05,
      "loss": 0.1995,
      "step": 3575
    },
    {
      "epoch": 0.6328001406222534,
      "grad_norm": 3.138632297515869,
      "learning_rate": 7.361574969238882e-05,
      "loss": 0.2046,
      "step": 3600
    },
    {
      "epoch": 0.6371945860432413,
      "grad_norm": 2.0865087509155273,
      "learning_rate": 7.273686060819125e-05,
      "loss": 0.2045,
      "step": 3625
    },
    {
      "epoch": 0.6415890314642292,
      "grad_norm": 3.1302056312561035,
      "learning_rate": 7.185797152399367e-05,
      "loss": 0.2052,
      "step": 3650
    },
    {
      "epoch": 0.6459834768852171,
      "grad_norm": 2.917149066925049,
      "learning_rate": 7.097908243979609e-05,
      "loss": 0.2012,
      "step": 3675
    },
    {
      "epoch": 0.650377922306205,
      "grad_norm": 3.2078888416290283,
      "learning_rate": 7.010019335559854e-05,
      "loss": 0.2111,
      "step": 3700
    },
    {
      "epoch": 0.6547723677271928,
      "grad_norm": 2.6348767280578613,
      "learning_rate": 6.922130427140096e-05,
      "loss": 0.1934,
      "step": 3725
    },
    {
      "epoch": 0.6591668131481807,
      "grad_norm": 3.238131046295166,
      "learning_rate": 6.834241518720337e-05,
      "loss": 0.1995,
      "step": 3750
    },
    {
      "epoch": 0.6635612585691686,
      "grad_norm": 2.8795156478881836,
      "learning_rate": 6.74635261030058e-05,
      "loss": 0.2077,
      "step": 3775
    },
    {
      "epoch": 0.6679557039901565,
      "grad_norm": 2.9358837604522705,
      "learning_rate": 6.658463701880822e-05,
      "loss": 0.2064,
      "step": 3800
    },
    {
      "epoch": 0.6723501494111443,
      "grad_norm": 2.6951608657836914,
      "learning_rate": 6.570574793461066e-05,
      "loss": 0.1954,
      "step": 3825
    },
    {
      "epoch": 0.6767445948321322,
      "grad_norm": 3.461014986038208,
      "learning_rate": 6.482685885041309e-05,
      "loss": 0.2033,
      "step": 3850
    },
    {
      "epoch": 0.6811390402531201,
      "grad_norm": 1.9515511989593506,
      "learning_rate": 6.394796976621551e-05,
      "loss": 0.2087,
      "step": 3875
    },
    {
      "epoch": 0.6855334856741079,
      "grad_norm": 3.6758525371551514,
      "learning_rate": 6.306908068201794e-05,
      "loss": 0.2031,
      "step": 3900
    },
    {
      "epoch": 0.6899279310950958,
      "grad_norm": 2.947429895401001,
      "learning_rate": 6.219019159782036e-05,
      "loss": 0.2009,
      "step": 3925
    },
    {
      "epoch": 0.6943223765160836,
      "grad_norm": 2.0481576919555664,
      "learning_rate": 6.131130251362278e-05,
      "loss": 0.1879,
      "step": 3950
    },
    {
      "epoch": 0.6987168219370715,
      "grad_norm": 1.3467185497283936,
      "learning_rate": 6.04324134294252e-05,
      "loss": 0.1876,
      "step": 3975
    },
    {
      "epoch": 0.7031112673580594,
      "grad_norm": 2.9033195972442627,
      "learning_rate": 5.955352434522764e-05,
      "loss": 0.1945,
      "step": 4000
    },
    {
      "epoch": 0.7075057127790473,
      "grad_norm": 1.9921759366989136,
      "learning_rate": 5.867463526103007e-05,
      "loss": 0.1848,
      "step": 4025
    },
    {
      "epoch": 0.7119001582000352,
      "grad_norm": 3.1852681636810303,
      "learning_rate": 5.7795746176832485e-05,
      "loss": 0.2104,
      "step": 4050
    },
    {
      "epoch": 0.716294603621023,
      "grad_norm": 3.4241223335266113,
      "learning_rate": 5.691685709263491e-05,
      "loss": 0.1919,
      "step": 4075
    },
    {
      "epoch": 0.7206890490420109,
      "grad_norm": 2.6789748668670654,
      "learning_rate": 5.6037968008437336e-05,
      "loss": 0.1978,
      "step": 4100
    },
    {
      "epoch": 0.7250834944629988,
      "grad_norm": 3.026455879211426,
      "learning_rate": 5.515907892423976e-05,
      "loss": 0.1933,
      "step": 4125
    },
    {
      "epoch": 0.7294779398839867,
      "grad_norm": 2.3627986907958984,
      "learning_rate": 5.428018984004219e-05,
      "loss": 0.2025,
      "step": 4150
    },
    {
      "epoch": 0.7338723853049746,
      "grad_norm": 2.5169177055358887,
      "learning_rate": 5.340130075584462e-05,
      "loss": 0.1964,
      "step": 4175
    },
    {
      "epoch": 0.7382668307259623,
      "grad_norm": 3.086090087890625,
      "learning_rate": 5.2522411671647044e-05,
      "loss": 0.2061,
      "step": 4200
    },
    {
      "epoch": 0.7426612761469502,
      "grad_norm": 2.7640345096588135,
      "learning_rate": 5.164352258744947e-05,
      "loss": 0.1885,
      "step": 4225
    },
    {
      "epoch": 0.7470557215679381,
      "grad_norm": 3.044189214706421,
      "learning_rate": 5.076463350325189e-05,
      "loss": 0.2022,
      "step": 4250
    },
    {
      "epoch": 0.751450166988926,
      "grad_norm": 4.330558776855469,
      "learning_rate": 4.988574441905432e-05,
      "loss": 0.1929,
      "step": 4275
    },
    {
      "epoch": 0.7558446124099139,
      "grad_norm": 3.260165214538574,
      "learning_rate": 4.9006855334856746e-05,
      "loss": 0.1943,
      "step": 4300
    },
    {
      "epoch": 0.7602390578309017,
      "grad_norm": 2.0797362327575684,
      "learning_rate": 4.8127966250659164e-05,
      "loss": 0.1879,
      "step": 4325
    },
    {
      "epoch": 0.7646335032518896,
      "grad_norm": 2.7226755619049072,
      "learning_rate": 4.7249077166461597e-05,
      "loss": 0.1883,
      "step": 4350
    },
    {
      "epoch": 0.7690279486728775,
      "grad_norm": 2.6338138580322266,
      "learning_rate": 4.637018808226402e-05,
      "loss": 0.2039,
      "step": 4375
    },
    {
      "epoch": 0.7734223940938654,
      "grad_norm": 2.4313273429870605,
      "learning_rate": 4.549129899806645e-05,
      "loss": 0.1866,
      "step": 4400
    },
    {
      "epoch": 0.7778168395148533,
      "grad_norm": 3.159057378768921,
      "learning_rate": 4.461240991386887e-05,
      "loss": 0.1926,
      "step": 4425
    },
    {
      "epoch": 0.7822112849358411,
      "grad_norm": 3.0379574298858643,
      "learning_rate": 4.37335208296713e-05,
      "loss": 0.181,
      "step": 4450
    },
    {
      "epoch": 0.786605730356829,
      "grad_norm": 2.9780802726745605,
      "learning_rate": 4.2854631745473723e-05,
      "loss": 0.1948,
      "step": 4475
    },
    {
      "epoch": 0.7910001757778169,
      "grad_norm": 2.1276214122772217,
      "learning_rate": 4.197574266127615e-05,
      "loss": 0.1828,
      "step": 4500
    },
    {
      "epoch": 0.7953946211988047,
      "grad_norm": 3.1594126224517822,
      "learning_rate": 4.1096853577078574e-05,
      "loss": 0.1814,
      "step": 4525
    },
    {
      "epoch": 0.7997890666197925,
      "grad_norm": 3.564300298690796,
      "learning_rate": 4.0217964492881e-05,
      "loss": 0.1898,
      "step": 4550
    },
    {
      "epoch": 0.8041835120407804,
      "grad_norm": 3.9727721214294434,
      "learning_rate": 3.9339075408683425e-05,
      "loss": 0.1892,
      "step": 4575
    },
    {
      "epoch": 0.8085779574617683,
      "grad_norm": 2.732839584350586,
      "learning_rate": 3.846018632448585e-05,
      "loss": 0.1907,
      "step": 4600
    },
    {
      "epoch": 0.8129724028827562,
      "grad_norm": 2.5878045558929443,
      "learning_rate": 3.7581297240288276e-05,
      "loss": 0.1838,
      "step": 4625
    },
    {
      "epoch": 0.8173668483037441,
      "grad_norm": 2.439028263092041,
      "learning_rate": 3.67024081560907e-05,
      "loss": 0.1846,
      "step": 4650
    },
    {
      "epoch": 0.821761293724732,
      "grad_norm": 2.331181049346924,
      "learning_rate": 3.582351907189313e-05,
      "loss": 0.1858,
      "step": 4675
    },
    {
      "epoch": 0.8261557391457198,
      "grad_norm": 1.7411994934082031,
      "learning_rate": 3.494462998769555e-05,
      "loss": 0.185,
      "step": 4700
    },
    {
      "epoch": 0.8305501845667077,
      "grad_norm": 2.4501702785491943,
      "learning_rate": 3.406574090349798e-05,
      "loss": 0.1848,
      "step": 4725
    },
    {
      "epoch": 0.8349446299876956,
      "grad_norm": 2.9086129665374756,
      "learning_rate": 3.318685181930041e-05,
      "loss": 0.1912,
      "step": 4750
    },
    {
      "epoch": 0.8393390754086835,
      "grad_norm": 2.8717474937438965,
      "learning_rate": 3.2307962735102835e-05,
      "loss": 0.1975,
      "step": 4775
    },
    {
      "epoch": 0.8437335208296713,
      "grad_norm": 1.4799864292144775,
      "learning_rate": 3.142907365090525e-05,
      "loss": 0.1795,
      "step": 4800
    },
    {
      "epoch": 0.8481279662506591,
      "grad_norm": 3.1947240829467773,
      "learning_rate": 3.0550184566707685e-05,
      "loss": 0.1785,
      "step": 4825
    },
    {
      "epoch": 0.852522411671647,
      "grad_norm": 3.271543264389038,
      "learning_rate": 2.9671295482510107e-05,
      "loss": 0.1789,
      "step": 4850
    },
    {
      "epoch": 0.8569168570926349,
      "grad_norm": 1.6475411653518677,
      "learning_rate": 2.8792406398312533e-05,
      "loss": 0.1856,
      "step": 4875
    },
    {
      "epoch": 0.8613113025136228,
      "grad_norm": 4.072809219360352,
      "learning_rate": 2.791351731411496e-05,
      "loss": 0.192,
      "step": 4900
    },
    {
      "epoch": 0.8657057479346106,
      "grad_norm": 2.2620837688446045,
      "learning_rate": 2.7034628229917387e-05,
      "loss": 0.1779,
      "step": 4925
    },
    {
      "epoch": 0.8701001933555985,
      "grad_norm": 2.3978018760681152,
      "learning_rate": 2.615573914571981e-05,
      "loss": 0.1897,
      "step": 4950
    },
    {
      "epoch": 0.8744946387765864,
      "grad_norm": 3.125950336456299,
      "learning_rate": 2.527685006152224e-05,
      "loss": 0.1784,
      "step": 4975
    },
    {
      "epoch": 0.8788890841975743,
      "grad_norm": 3.314542293548584,
      "learning_rate": 2.4397960977324663e-05,
      "loss": 0.1915,
      "step": 5000
    },
    {
      "epoch": 0.8832835296185622,
      "grad_norm": 1.7503308057785034,
      "learning_rate": 2.3519071893127088e-05,
      "loss": 0.1827,
      "step": 5025
    },
    {
      "epoch": 0.88767797503955,
      "grad_norm": 2.423211097717285,
      "learning_rate": 2.2640182808929514e-05,
      "loss": 0.1841,
      "step": 5050
    },
    {
      "epoch": 0.8920724204605379,
      "grad_norm": 2.854384183883667,
      "learning_rate": 2.176129372473194e-05,
      "loss": 0.1905,
      "step": 5075
    },
    {
      "epoch": 0.8964668658815258,
      "grad_norm": 2.1590771675109863,
      "learning_rate": 2.0882404640534364e-05,
      "loss": 0.1774,
      "step": 5100
    },
    {
      "epoch": 0.9008613113025136,
      "grad_norm": 3.8905677795410156,
      "learning_rate": 2.000351555633679e-05,
      "loss": 0.1867,
      "step": 5125
    },
    {
      "epoch": 0.9052557567235014,
      "grad_norm": 2.1160569190979004,
      "learning_rate": 1.912462647213922e-05,
      "loss": 0.1805,
      "step": 5150
    },
    {
      "epoch": 0.9096502021444893,
      "grad_norm": 3.2490758895874023,
      "learning_rate": 1.824573738794164e-05,
      "loss": 0.1795,
      "step": 5175
    },
    {
      "epoch": 0.9140446475654772,
      "grad_norm": 2.7817602157592773,
      "learning_rate": 1.736684830374407e-05,
      "loss": 0.1909,
      "step": 5200
    },
    {
      "epoch": 0.9184390929864651,
      "grad_norm": 1.8537594079971313,
      "learning_rate": 1.6487959219546495e-05,
      "loss": 0.1746,
      "step": 5225
    },
    {
      "epoch": 0.922833538407453,
      "grad_norm": 2.4454469680786133,
      "learning_rate": 1.560907013534892e-05,
      "loss": 0.1753,
      "step": 5250
    },
    {
      "epoch": 0.9272279838284408,
      "grad_norm": 2.245471954345703,
      "learning_rate": 1.4730181051151345e-05,
      "loss": 0.1726,
      "step": 5275
    },
    {
      "epoch": 0.9316224292494287,
      "grad_norm": 1.865143060684204,
      "learning_rate": 1.3851291966953772e-05,
      "loss": 0.1812,
      "step": 5300
    },
    {
      "epoch": 0.9360168746704166,
      "grad_norm": 3.4295578002929688,
      "learning_rate": 1.2972402882756196e-05,
      "loss": 0.182,
      "step": 5325
    },
    {
      "epoch": 0.9404113200914045,
      "grad_norm": 2.5418541431427,
      "learning_rate": 1.2093513798558623e-05,
      "loss": 0.1939,
      "step": 5350
    },
    {
      "epoch": 0.9448057655123924,
      "grad_norm": 2.773017644882202,
      "learning_rate": 1.1214624714361048e-05,
      "loss": 0.1754,
      "step": 5375
    },
    {
      "epoch": 0.9492002109333803,
      "grad_norm": 2.7483482360839844,
      "learning_rate": 1.0335735630163474e-05,
      "loss": 0.1977,
      "step": 5400
    },
    {
      "epoch": 0.9535946563543681,
      "grad_norm": 2.9925549030303955,
      "learning_rate": 9.4568465459659e-06,
      "loss": 0.1869,
      "step": 5425
    },
    {
      "epoch": 0.9579891017753559,
      "grad_norm": 2.753422498703003,
      "learning_rate": 8.577957461768325e-06,
      "loss": 0.181,
      "step": 5450
    },
    {
      "epoch": 0.9623835471963438,
      "grad_norm": 2.992119073867798,
      "learning_rate": 7.69906837757075e-06,
      "loss": 0.1824,
      "step": 5475
    },
    {
      "epoch": 0.9667779926173317,
      "grad_norm": 3.1851511001586914,
      "learning_rate": 6.820179293373177e-06,
      "loss": 0.1893,
      "step": 5500
    },
    {
      "epoch": 0.9711724380383195,
      "grad_norm": 1.9530439376831055,
      "learning_rate": 5.941290209175602e-06,
      "loss": 0.1868,
      "step": 5525
    },
    {
      "epoch": 0.9755668834593074,
      "grad_norm": 2.2639737129211426,
      "learning_rate": 5.062401124978028e-06,
      "loss": 0.1806,
      "step": 5550
    },
    {
      "epoch": 0.9799613288802953,
      "grad_norm": 2.440601348876953,
      "learning_rate": 4.183512040780454e-06,
      "loss": 0.1871,
      "step": 5575
    },
    {
      "epoch": 0.9843557743012832,
      "grad_norm": 2.1419012546539307,
      "learning_rate": 3.3046229565828793e-06,
      "loss": 0.1923,
      "step": 5600
    },
    {
      "epoch": 0.9887502197222711,
      "grad_norm": 1.8264853954315186,
      "learning_rate": 2.425733872385305e-06,
      "loss": 0.1929,
      "step": 5625
    },
    {
      "epoch": 0.9931446651432589,
      "grad_norm": 2.2502431869506836,
      "learning_rate": 1.5468447881877309e-06,
      "loss": 0.1884,
      "step": 5650
    },
    {
      "epoch": 0.9975391105642468,
      "grad_norm": 2.99381947517395,
      "learning_rate": 6.679557039901565e-07,
      "loss": 0.1887,
      "step": 5675
    }
  ],
  "logging_steps": 25,
  "max_steps": 5689,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.950561664573112e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
